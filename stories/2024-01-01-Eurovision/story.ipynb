{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Eurovision Turing Data Story\n",
                "\n",
                "> Exploring (non-musical) factors contributing to Eurovision votes in the past 25 years.\n",
                "\n",
                "- toc: false\n",
                "- categories: [data wrangling, data visualisation, bayesian modeling, random forest, eurovision]\n",
                "- author(s): Ed Chapman, Katriona Goldmann, Radka Jersakova, David Llewellyn-Jones, Joe Palmer, Camila Rangel Smith, Martin Stoffel, Jonathan Yong\n",
                "- image: TODO\n",
                "\n",
                "**Authors**\n",
                " - Ed Chapman\n",
                " - Katriona Goldmann\n",
                " - Radka Jersakova\n",
                " - David Llewellyn-Jones\n",
                " - Joe Palmer\n",
                " - Camila Rangel Smith\n",
                " - Martin Stoffel\n",
                " - Jonathan Yong\n",
                " \n",
                " **Reviewers:**\n",
                "- Reviewer 1\n",
                "- Reviewer 2"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction\n",
                "\n",
                "The Eurovision Song Contest, or *Eurovision* for short, is an annual competition featuring (mostly) European countries. It is in fact the longest running international televised music competition, having started in 1951 as what was then seen as a technical experiment in transnational live broadcasting. The competition has continued every year since &mdash; except in 2020 when it was cancelled, [much to Iceland's chagrin](https://youtu.be/1HU7ocv3S2o), due to the pandemic &mdash; and has grown in terms of number of countries participating, musical variety, visual flair and (some might say) fantastical preposterousness.\n",
                "\n",
                "Despite the name, the Eurovision Song Content is neither about Europe, nor Singing. According to the Eurovision website, the European Broadcasting Union which runs the contest is made up of \"56 countries and an additional 31 Associates in Asia, Africa, Australasia and the Americas\". The contest itself is billed as a *songwriting* competition.\n",
                "\n",
                "There are [strict requirements](https://eurovision.tv/about/rules) that songs and performers must comply with. Songs must be original; under three minutes long; sung live without lip syncing and with no live plugging instruments.\n",
                "\n",
                "Typically the winning country is expected to host the technically challenging and costly event the following year (a 'prize' that [allegedly led to](https://www.irelandbeforeyoudie.com/why-ireland-stopped-winning-eurovision/) Ireland entering sub-par acts for at least a decade in a deliberate attempt to avoid winning). As many readers will no-doubt be aware, in 2022 the competition was won by Kalush Orchestra from Ukraine, with their song [Stefania](https://youtu.be/F1fl60ypdLs). This would ordinarily mean the 2023 event would have been held in Ukraine, however this was deemed unsafe in light of the Russian invasion. The UK (the 2022 runners-up) therefore stepped in, meaning that in 2023 the contest was held in Liverpool, 9–13 May.\n",
                "\n",
                "The seventy-year history of the event means there is now a large body of data about it to work with, as well as a large number of great songs to listen to. As you work through this Turing Data Story, we strongly recommend you listen to some of the great Eurovision masterpieces as your backing track, from the likes of [Celine Dion](https://youtu.be/w6b7BHGkKQA), [Bucks Fizz](https://youtu.be/h4-lKMGII_k), [Lordi](https://youtu.be/gAh9NRGNhUU), [Loreen](https://youtu.be/Pfo-8z86x80) and of course [Abba](https://youtu.be/Vp1_OKawHYw).\n",
                "\n",
                "<center>\n",
                "    <img alt=\"meme comparing what I think I look like discussing eurovision: two men casually talking to sofa; to what I actually look like: Charlie Kelly looking wild-eyed in front of a peg board full of conspiracy connections\" src=\"https://i.imgur.com/WVNzMI7.jpeg\" />\n",
                "</center>\n",
                "\n",
                "In the current format, participating countries first take part in a semifinal; the top 10 from each semifinal qualify for the finals.\n",
                "The host country, as well as the \"Big Five\" (France, Germany, Italy, Spain, and the UK, which make greater financial contributions), directly qualify for the finals.\n",
                "\n",
                "We have pooled data from a number of different sources with the aim of understanding trends in the contest voting patterns. We have also tried to make the data as accessible as possible. The curated data frame is available in the `data/df_main.csv` file, and the code to create this dataset is in `data.ipynb`.\n",
                "\n",
                "We used this dataset to predict the winners of the [2023 event in Liverpool](https://eurovision.tv/event/liverpool-2023). Now that the event has taken place we've left this analysis as-is, so that you can compare our predictions with the actual results. But we've also now been able to add some post-match analysis to reflect on how our models did so that we can be even more accurate next year.\n",
                "\n",
                "In this notebook we'll go into some detail about all of our data collection, analysis and results. If you're here for instant gratification and just want to know how we did, check out our summary on the [Turing Institute Blog](https://www.turing.ac.uk/blog/can-data-science-help-us-predict-winner-eurovision-2023). But if you want to know all the gory data-sciency details, then read on!"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "We begin by importing packages and setting up any configuration needed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib.lines import Line2D\n",
                "from pathlib import Path\n",
                "import seaborn as sns\n",
                "from IPython.display import clear_output\n",
                "import scipy\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data\n",
                "\n",
                "In order to explore the characteristics of Eurovision, with the aim of making predictions for the 2023 event, we first need to collect historical data about contests prior to 2023. We will obviously need to know what scores were assigned to which acts in previous years, but we also want to explore other factors that might potentially affect the success or otherwise of the performances.\n",
                "\n",
                "It has long [been claimed](https://www.datalytyx.com/eurovision-song-contest-regression-analysis-highlights-the-voting-patterns/) that there is a [measurable bias](https://www.tandfonline.com/doi/full/10.1080/02664763.2014.909792) in relation to which countries vote for which other countries at Eurovision. We should therefore gather data that exhibits these biases. We also consider other factors that may affect voting patterns, such as the gender of the performer or language of the song.\n",
                "\n",
                "The Eurovision Song Contest has undergone several changes to its voting system since it began in 1956. These changes were made to increase transparency and reduce the impact of regional bloc voting, while still allowing for a fair and entertaining competition.\n",
                "\n",
                "In the early years, the winning country was selected by a jury of experts from each participating country. In 1975, a new system was introduced that combined jury voting with telephone voting by viewers at home. Over time, the weight of the jury and viewer votes has shifted, with viewer votes becoming more influential. In 2016, the voting system was revised again, with separate scores given for jury and viewer votes, and a new system for calculating the final scores. \n",
                "\n",
                "In order to model uniform voting scores over time, we limited our analysis to contests from 1998 onwards, where the jury and televoting scores are equally weighted.\n",
                "\n",
                "In the following sections we'll describe our data-wrangling efforts in some depth. If you're more interested in the analysis, then you can safely skip forwards to the [Covariate visualisation section](#Covariate-visualisation) without losing the narrative."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Voting Scores\n",
                "\n",
                "Our voting data was pulled from the following sources: \n",
                "\n",
                "- From the [Eurovision Song Contest Scores Kaggle dataset](https://www.kaggle.com/datasets/datagraver/eurovision-song-contest-scores-19752019), for the years 1998–2019. \n",
                "- The 2020 contest was cancelled due to Covid. \n",
                "- The [2021](https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2021#Final_2) and [2022](https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2022#Final_2) contest scores were scraped from Wikipedia.\n",
                "\n",
                "The jury votes have in the past been replaced with a substitute aggregate due to potential bias or 'irregularities'. In this case, new jury scores were calculated [\"based on the results of other countries with similar voting records\"](https://eurovision.tv/mediacentre/release/ebu-statement-voting-during-2022-shows). However, this is not very transparent and [not captured by our models](https://eurovisionworld.com/esc/here-is-the-proof-of-the-eurovision-voting-scandal-six-juries-cheated-and-voted-for-each-other).\n",
                "\n",
                "Unlike in earlier years, since 2016 the jury and televoting scores have been reported separately. Simply summing these would lead to scores that are unusually large compared to previous years. In order to bring this in line, both votes were summed and rescaled by mapping the highest result to 12 points, second-highest to 10 points, and so on.\n",
                "\n",
                "For the data collection process the code is hidden for brevity, but available by opening out the sections in case you still want to view it.\n",
                "\n",
                "To begin we load in the Kaggle data which we host ourself to avoid having to negotiate with Kaggle's authentication wall."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "## Read in data from the Kaggle dataset\n",
                "votes_1975_2019 = pd.read_excel('data/eurovision_song_contest_1975_2019.xlsx', engine='openpyxl')\n",
                "print('Number of entries: {}'.format(len(votes_1975_2019)))\n",
                "votes_1975_2019.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The dataset requires some cleaning up before we can properly make use of it. Some of this is due to errors that have crept into the dataset such as incorrect spellings of country names, some is due to geopolitical changes during the period we're considering (we have mapped all entries by the entity 'Serbia & Montenegro' to Yugoslavia), and some is needed to get the dataset structured appropriately for our analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# Clean up the column names\n",
                "votes_1975_2019.columns = [c.strip().lower().replace(' ', '_') for c in votes_1975_2019.columns.values.tolist()]\n",
                "\n",
                "# Select only finals votes, and only 1998 onwards (inclusive)\n",
                "votes_1998_2019 = votes_1975_2019[(votes_1975_2019['(semi-)_final'] == 'f') & (votes_1975_2019['year'] >= 1998)]\n",
                "\n",
                "# Drop unnecessary columns\n",
                "votes_1998_2019 = votes_1998_2019[[\"year\", \"from_country\", \"to_country\", \"points\", \"jury_or_televoting\"]]\n",
                "\n",
                "# Clean up country names\n",
                "def standardise_country(c):\n",
                "    replacements = [('-', ' '), ('&', 'and'), ('Netherands', 'Netherlands'),\n",
                "                    # FYR Macedonia was formally renamed as North Macedonia in 2019\n",
                "                    ('F.Y.R. Macedonia', 'North Macedonia'), \n",
                "                    ('Russia', 'Russian Federation'), \n",
                "                    ('The Netherlands', 'Netherlands'), \n",
                "                    ('Czech Republic', 'Czechia'),\n",
                "                    # Yugoslavia dissolved in 2002; most of it became 'Serbia and Montenegro', until 2006, when Serbia and Montenegro split ways.\n",
                "                    ('Serbia and Montenegro', 'yugoslavia'),\n",
                "                    ('moldova', 'moldova, republic of')]\n",
                "    for r in replacements:\n",
                "        c = c.replace(r[0], r[1])\n",
                "    return c.lower()\n",
                "\n",
                "votes_1998_2019[['from_country', 'to_country']] = votes_1998_2019[['from_country', 'to_country']].applymap(standardise_country)\n",
                "\n",
                "# Drop columns which correspond to the same vote (there are two Belarus -> Russia in 2019, for example)\n",
                "votes_1998_2019 = votes_1998_2019.drop_duplicates(subset=['year', 'from_country', 'to_country', 'jury_or_televoting'])\n",
                "\n",
                "# Drop Lithuania in 2003 (they didn't participate - we don't know why it's still in the dataset)\n",
                "votes_1998_2019 = votes_1998_2019[~((votes_1998_2019['to_country'] == 'lithuania') & (votes_1998_2019['year'] == 2003))]\n",
                "\n",
                "# Drop \"votes\" from one country to itself\n",
                "votes_1998_2019 = votes_1998_2019[votes_1998_2019['from_country'] != votes_1998_2019['to_country']]\n",
                "\n",
                "votes_1998_2019.sample(n=10)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The Kaggle dataset runs up to 2019, but we need data for 2021 and 2022 as well (recall that there was no contest in 2020). We collect these data from the tables in the Wikipedia pages for the [2021](https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2021#Final_2) and [2022](https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2022#Final_2) contests respectively.\n",
                "\n",
                "The process of downloading and cleaning up this data is rather long winded, so we're going to skip past that here and instead refer to the separate [data collection notebook](https://github.com/KatrionaGoldmann/Eurovision_TDS/blob/story_notebook/eurovision/notebooks/data.ipynb) that we've put together for the inquisitve.\n",
                "\n",
                "So we'll short-circuit this by grabbing the output from the data collection notebook. Or, in the immortal words of the Blue Peter team, here's one I made earlier:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "votes = pd.read_csv('data/votes.csv')\n",
                "votes.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Performance language\n",
                "\n",
                "The next step is to collect together the languages used in the songs. We're particularly interested in whether the song is sung in the language of the performing country or some other language. Anecdotally there has been a tendency for songs to be sung in English if not a country's native language, and so we also keep track of whether a song includes English lyrics as well.\n",
                "\n",
                "When collecting the data, we have to bear in mind that songs are often sung in *more than one* language. The fields we've chosen to populate are therefore:\n",
                " - *whether the song contains English lyrics*,\n",
                " - *whether it contains non-English lyrics*,\n",
                " - *whether it contains the performing country's official language*,\n",
                " - *whether it contains the voting country's official language*, and\n",
                " - *whether it contains multiple languages*.\n",
                "\n",
                "We retreived information about the language of each performance from a dataset [available from Kaggle](https://www.kaggle.com/datasets/minitree/eurovision-song-lyrics?select=eurovision-lyrics-2022.json). This provides us with half of our needs; the other half relates to which languages are the official languages of each country. For the latter we scrape the list of official languages available [on Wikipedia](https://en.wikipedia.org/wiki/List_of_official_languages_by_country_and_territory).\n",
                "\n",
                "Again, the data needed considerable cleaning and structuring to suit our needs. We'll skip the code for doing this for brevity and refer the interested reader to our data collection notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "df_VL = pd.read_csv('data/language.csv')\n",
                "df_VL.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Performer gender\n",
                "\n",
                "To establish the gender of the various performers we capture the *'gender'* property available from [Wikidata](https://www.wikidata.org/wiki/Wikidata:List_of_properties), using code that's based on Sam Van Stroud's [wikipeople script](https://github.com/samvanstroud/wikipeople/blob/master/wikipeople/wikipeople.py).\n",
                "\n",
                "Rather than referring directly to our [data collection notebook](https://github.com/KatrionaGoldmann/Eurovision_TDS/blob/story_notebook/eurovision/notebooks/data.ipynb) we've kept the code here, since it demonstrates some nice techniques. You'll still need to unfold the cells to view the details.\n",
                "\n",
                "Establishing gender isn't straightforward in all cases. For example, many Eurovision entries are group performances. For these we detect the *'instance of'* Wikidata property, checking whether it's equal to one of *group*, *duo*, *trio*, *music*, *band* or *ensemble*. There are also non-binary performers to consider.\n",
                "\n",
                "Searching Wikidata with a name often generates multiple hits, so we try to restrict our search to performers tagged as being musicians and tagged as having performed at Eurovision. Even with this restriction we don't always get a unique hit, or any hit at all. Some artists simply don't exist in the database, or are missing these tags. Out of the total 600 performers we are left having to manually assign genders to 55 of them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "import aiohttp\n",
                "import asyncio\n",
                "\n",
                "async def get_property(session, concept_id, property_id):\n",
                "    \"\"\"Async reimplementation of wikipeople.get_property\n",
                "    https://github.com/samvanstroud/wikipeople/blob/master/wikipeople/wikipeople.py\n",
                "\n",
                "    session is an aiohttp ClientSession instance.\n",
                "    concept_id refers to a person or a group, and can be obtained using the get_concept_id function.\n",
                "    property_id refers to a certain property of the given entity referred to by the concept_id.\n",
                "\n",
                "    Returns None if any of this can't be found for whatever reason.\n",
                "\n",
                "    e.g. \"Q219655\" is the concept_id for Carey Mulligan; \"P21\" is the property_id for gender.\n",
                "    So we have that get_property(session, \"Q219655\", \"P21\") -> \"female\".\n",
                "    \"\"\"\n",
                "    url = \"https://www.wikidata.org/w/api.php\"\n",
                "    params = {\n",
                "        \"action\": \"wbgetclaims\",\n",
                "        \"entity\": concept_id,\n",
                "        \"property\": property_id,\n",
                "        \"language\": \"en\",\n",
                "        \"format\": \"json\",\n",
                "    }\n",
                "    async with session.get(url, params=params) as resp:\n",
                "        try:\n",
                "            res = await resp.json()\n",
                "        except Exception as e:\n",
                "            print(resp)\n",
                "            raise e\n",
                "\n",
                "    if property_id not in res[\"claims\"]:\n",
                "        return None\n",
                "    # This gives yet another 'id', and we then need to perform yet another HTTP\n",
                "    # request to find the actual *label* that this corresponds to.\n",
                "    else:\n",
                "        id = None\n",
                "        for prop in res[\"claims\"][property_id]:\n",
                "            try:\n",
                "                id = prop[\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
                "            except:\n",
                "                continue\n",
                "\n",
                "        if id is None:\n",
                "            return None\n",
                "        else:\n",
                "            new_params = {\n",
                "                \"action\": \"wbgetentities\",\n",
                "                \"ids\": id,\n",
                "                \"languages\": \"en\",\n",
                "                \"format\": \"json\",\n",
                "                \"props\": \"labels\",\n",
                "            }\n",
                "            async with session.get(url, params=new_params) as resp:\n",
                "                try:\n",
                "                    res = await resp.json()\n",
                "                except Exception as e:\n",
                "                    print(resp)\n",
                "                    raise e\n",
                "            try:\n",
                "                return res[\"entities\"][id][\"labels\"][\"en\"][\"value\"]\n",
                "            except:\n",
                "                return None\n",
                "\n",
                "\n",
                "async def get_concept_id(session, page_name):\n",
                "    \"\"\"\n",
                "    Get the concept_id corresponding to a particular Wikipedia page. For some odd reason, some Wikipedia\n",
                "    pages don't have concept IDs. In such a case, we return None.\n",
                "\n",
                "    e.g. get_concept_id(session, \"Carey Mulligan\") -> \"Q219655\"\n",
                "    \"\"\"\n",
                "    url = \"https://www.wikidata.org/w/api.php\"\n",
                "    params = {\n",
                "        \"action\": \"wbsearchentities\",\n",
                "        \"search\": page_name,\n",
                "        \"language\": \"en\",\n",
                "        \"format\": \"json\",\n",
                "    }\n",
                "    music_markers = [\n",
                "        \"singer\",\n",
                "        \"artist\",\n",
                "        \"musician\",\n",
                "        \"music\",\n",
                "        \"band\",\n",
                "        \"group\",\n",
                "        \"duo\",\n",
                "        \"ensemble\",\n",
                "    ]\n",
                "\n",
                "    async with session.get(url, params=params) as resp:\n",
                "        # Titles of WP pages that match the search query.\n",
                "        json = await resp.json()\n",
                "\n",
                "    result = json[\"search\"]\n",
                "\n",
                "    if len(result) == 0:\n",
                "        # Couldn't find a concept id for the person/group\n",
                "        return None\n",
                "\n",
                "    # By default, choose the first result from the list\n",
                "    target = 0\n",
                "    # But check the other results to see if any of them are musicians (as\n",
                "    # indicated by the markers) and Eurovision contestants\n",
                "    for i, res in enumerate(result):\n",
                "        if \"description\" in res[\"display\"]:\n",
                "            description = res[\"display\"][\"description\"][\"value\"]\n",
                "            if any(markers in description for markers in music_markers):\n",
                "                concept_id = res[\"id\"]\n",
                "                contestant_in = await get_property(session, concept_id, \"P1344\")\n",
                "                if contestant_in is not None and \"Eurovision\" in contestant_in:\n",
                "                    target = i\n",
                "    # Return the concept ID of the result found\n",
                "    return result[target][\"id\"]\n",
                "\n",
                "\n",
                "async def lookup_gender(session, page_name):\n",
                "    \"\"\"Find gender of a performing act, using the name associated with their\n",
                "    Wikipedia page. Returns None if could not be found.\n",
                "    \"\"\"\n",
                "    concept_id = await get_concept_id(session, page_name)\n",
                "    if concept_id is None:\n",
                "        return None\n",
                "\n",
                "    gender = await get_property(session, concept_id, \"P21\")\n",
                "    instance = await get_property(session, concept_id, \"P31\")\n",
                "    if gender is None and instance is None:\n",
                "        return None\n",
                "    elif gender is None and instance is not None:\n",
                "        group_checks = [\"group\", \"duo\", \"trio\", \"music\", \"band\", \"ensemble\"]\n",
                "        if any(x in instance for x in group_checks):\n",
                "            return \"group\"\n",
                "    else:\n",
                "        return gender\n",
                "\n",
                "\n",
                "async def get_pages(session, name):\n",
                "    \"\"\"Obtain a list of Wikipedia pages obtained by searching for a name.\"\"\"\n",
                "    url = \"https://en.wikipedia.org/w/api.php\"\n",
                "    params = {\n",
                "        \"action\": \"opensearch\",\n",
                "        \"namespace\": \"0\",\n",
                "        \"search\": name,\n",
                "        \"limit\": \"10000\",\n",
                "        \"format\": \"json\",\n",
                "    }\n",
                "    async with session.get(url, params=params) as resp:\n",
                "        # Titles of WP pages that match the search query.\n",
                "        json = await resp.json()\n",
                "    return json[1]\n",
                "\n",
                "\n",
                "async def get_artist_gender(session, name):\n",
                "    gender = None\n",
                "    # Get the WP page for this person/group\n",
                "    pages = await get_pages(session, name)\n",
                "    # If there's one, try to get their gender from the first page\n",
                "    if len(pages) > 0:\n",
                "        gender = await lookup_gender(session, pages[0])\n",
                "    # Finally we use some heuristics to cover some edge cases\n",
                "    if gender is None:\n",
                "        if \"&\" in name or \"feat.\" in name:\n",
                "            return \"group\"\n",
                "\n",
                "    return gender"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The next bit of code pulls the list of artists from the data we already collected above. We use an async function to make multiple HTTP requests simultaneously and greatly decrease the overall time needed to work through the list.\n",
                "\n",
                "Having extracted as much as possible from Wikidata the code then performs the manual fixes to complete the missing entries, and to ensure transgender entries are regarded as simply *male* or *female* as appropriate. Finally the results are merged in with our existing data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "all_performers = df_VL['Artist'].unique().tolist()\n",
                "n_performers = len(all_performers)\n",
                "MAX_CONCURRENT = 40   # To stop Wikipedia from complaining about 'too many requests'\n",
                "USER_AGENT = 'Eurovision study @ The Alan Turing Institute mailto:jyong@turing.ac.uk'\n",
                "\n",
                "async def get_all_genders():\n",
                "    genders = []\n",
                "    print(f'Fetching genders of {n_performers} performers, in batches of {MAX_CONCURRENT}. Hold tight...')\n",
                "    async with aiohttp.ClientSession(headers={'User-Agent': USER_AGENT}) as session:\n",
                "        start = 0\n",
                "        end = MAX_CONCURRENT\n",
                "        while start < n_performers:\n",
                "            print(f'Getting genders for performers #{start + 1} to #{end}... ', end='')\n",
                "            batch_tasks = asyncio.gather(*[get_artist_gender(session, p) for p in all_performers[start:end]])\n",
                "            batch_genders = await batch_tasks\n",
                "            print(f'Got {len(batch_genders)} results, {len([g for g in batch_genders if g is None])} of which were None.')\n",
                "            genders = genders + batch_genders\n",
                "            start = end\n",
                "            end = min(end + MAX_CONCURRENT, n_performers)\n",
                "            await asyncio.sleep(1.5)   # Put a pause between batches to avoid being timed out\n",
                "\n",
                "    assert len(genders) == n_performers  # Check for off-by-one errors\n",
                "    print('Finished downloading gender data.')\n",
                "    clear_output(wait=True)\n",
                "    return dict(zip(all_performers, genders))\n",
                "\n",
                "gender_dict = await get_all_genders()\n",
                "\n",
                "# Manually assign missing entries (the Nones).\n",
                "male = ['Michael Hajiyanni', 'Charlie', 'Tüzmen', 'Mietek Szcześniak', 'Olexandr', 'Max', 'Brinck',\n",
                "        'Sakis Rouvas (2)', 'Gianluca', 'Frans', 'Chingiz', 'Mahmood', 'Serhat (2)', 'Miki', 'Stefan']\n",
                "female = ['Gunvor', 'Selma', 'Charlotte Nilsson (Perrelli)', 'Karolina', 'Laura', 'Rosa', 'Lou', 'Nicola',\n",
                "        'Karmen', 'Sanda', 'Ortal', 'Gracia', 'Chiara (2)', 'Hanna', 'Chiara (3)', 'Elena', 'Lena (2)',\n",
                "        'Birgit', 'Samra', 'ZAA Sanja Vučić', 'Anja', 'Alma', 'Netta', 'Michela', 'Efendi', 'Victoria',\n",
                "        'Destiny', 'Amanda Georgiadi Tenfjord', 'MARO']\n",
                "group = ['Eden', 'Voice', 'Taxi', 'One', 'Prime Minister', 'Fame', 'Regina (band)', 'ESDM',\n",
                "        'Tolmachevy Sisters', 'Minus One', 'AWS']\n",
                "for p in male:\n",
                "    gender_dict[p] = \"male\"\n",
                "for p in female:\n",
                "    gender_dict[p] = \"female\"\n",
                "for p in group:\n",
                "    gender_dict[p] = \"group\"\n",
                "\n",
                "# Wikipedia needs to learn that 'trans woman' is 'female'.\n",
                "for k, v in gender_dict.items():\n",
                "    if v == 'trans woman':\n",
                "        gender_dict[k] = 'female'\n",
                "\n",
                "# Add gender to the dataframe.\n",
                "df_VLG = df_VL.copy()\n",
                "df_VLG['gender'] = df_VLG['Artist'].map(gender_dict)\n",
                "df_VLG.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Migration data\n",
                "\n",
                "Migration data were gathered to report on the estimated migration betweeen each voting–performing country pair that have previously competed. \n",
                "\n",
                "Data were collected from two sources. First we took migration data from [Our World in Data](https://ourworldindata.org/migration) under the 'Explore data on where people migrate from and to' section. The underlying data originate from the UN. The data show the total number of immigrants in each country split by country of origin in the years 1990–2020, recorded at intervals of every 5 years.\n",
                "\n",
                "We clean up the data so that the country names match those we're already using and filter on countries that participate in Eurovision."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "migration = (pd.read_csv('data/migration-flows.csv')\n",
                "    .pipe(pd.melt, id_vars=['Country', 'Year'], var_name='Migration', value_name='Count')  # to long format\n",
                "    .loc[lambda x: x['Migration'].str.contains('Emigrants')]                               # filter for emigrant rows\n",
                "    .pipe(lambda x: x.rename(columns = {col: col.lower() for col in x.columns}))           # lowercase column names                                                         \n",
                "    .assign(migration = lambda x: x.migration.str.replace('Emigrants from ', ''))          # filter for emigrant rows                          \n",
                "    .rename(columns={'migration': 'emigrated_from', 'country': 'emigrated_to'})            # boil down to country name\n",
                "    .query('count >= 0')                                                                   # negative counts are just total emigrants from country\n",
                "    .pipe(lambda x: x.assign(count = x['count'].astype(int)))                              # convert count to int     \n",
                ")\n",
                "\n",
                "# Clean up country names\n",
                "for ft in ['from', 'to']:\n",
                "    migration[f'emigrated_{ft}'] = migration[f'emigrated_{ft}'].str.lower()\n",
                "    migration.loc[migration[f'emigrated_{ft}'] == 'moldova', f'emigrated_{ft}'] = 'moldova, republic of'\n",
                "    migration.loc[migration[f'emigrated_{ft}'] == 'russia', f'emigrated_{ft}'] = 'russian federation'\n",
                "\n",
                "# Remove non-Eurovision countries\n",
                "ev_countries = set(df_VLG['from_country']).union(set(df_VLG['to_country']))\n",
                "migration = migration[(migration['emigrated_to'].isin(ev_countries)) & (migration['emigrated_from'].isin(ev_countries))]\n",
                "\n",
                "# Add in country codes\n",
                "def get_country_codes(name):\n",
                "    return df_VLG[df_VLG['from_country'] == name].iloc[0][['from_code2', 'from_code3']]\n",
                "\n",
                "for ft in ['from', 'to']:\n",
                "    migration[f'emigrated_{ft}_code2'], migration[f'emigrated_{ft}_code3'] = zip(*migration[f'emigrated_{ft}'].map(get_country_codes))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We note that we're able to get data for all of the countries except Yugoslavia which is missing from the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "migration_countries = set(migration['emigrated_to']).union(set(migration['emigrated_from']))\n",
                "print('Eurovision countries without data: {}'.format(''.join(ev_countries - migration_countries)))  # No data for Yugoslavia."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In order to provide a fairer comparison we convert absolute migration numbers into proportions of the population size of each country. For this we also need country population data, which we collected from the [World Bank](https://data.worldbank.org/indicator/SP.POP.TOTL?end=2021&start=2021&view=map)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "pop_size = (pd.read_csv('data/pop_sizes.csv')\n",
                "           .iloc[:, 3:]\n",
                "           .rename(columns=lambda x: x.lower().replace(' ', '_'))\n",
                "           .pipe(pd.melt, id_vars=['country_code'], var_name='year', value_name='population')\n",
                "           .assign(year=lambda x: x['year'].apply(lambda y: y.split('_')[0]))\n",
                "           .assign(year=lambda x: x['year'].astype(int))\n",
                "           .rename(columns={'country_code': 'code3'})\n",
                "           .dropna()\n",
                "           .assign(population=lambda x: pd.to_numeric(x['population'], errors='coerce'))\n",
                ")\n",
                "\n",
                "migration_and_pop = (migration.merge(pop_size, left_on=['year', 'emigrated_to_code3'], right_on=['year', 'code3'], how='left')\n",
                "                    .rename(columns={'population': 'population_to'})\n",
                "                    .assign(prop_emigrants=lambda x: x['count'] / x['population_to'])\n",
                "                    )"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The UN migration data are recorded in five year intervals, so for each year of Eurovision data we assign the most recent recording. In essence, we end up repeating each row of the migration data five times, once for each of the following four years."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "migration_and_pop['migration_pop_year'] = migration_and_pop['year']\n",
                "\n",
                "total_migration_and_pop = migration_and_pop.copy()\n",
                "for i in range(1, 5):\n",
                "    next_migration_and_pop = migration_and_pop.copy()\n",
                "    next_migration_and_pop['year'] = next_migration_and_pop['year'] + i\n",
                "    total_migration_and_pop = pd.concat([total_migration_and_pop, next_migration_and_pop], ignore_index=True)\n",
                "\n",
                "total_migration_and_pop = total_migration_and_pop.sort_values(by=[\"emigrated_from\", \"emigrated_to\", \"year\"])\n",
                "total_migration_and_pop = total_migration_and_pop[['emigrated_from_code2', 'emigrated_to_code2', 'year', 'count', 'population_to', 'prop_emigrants', 'migration_pop_year']]\n",
                "\n",
                "# Output a sample of the data including only some of the more relevant columns\n",
                "total_migration_and_pop[['emigrated_to_code2', 'emigrated_from_code2', 'year', 'population_to', 'prop_emigrants']].sample(5)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally we integrate this with our existing dataset. We'll skip this step for brevity and pull the data in direction from the [data collection notebook](https://github.com/KatrionaGoldmann/Eurovision_TDS/blob/story_notebook/eurovision/notebooks/data.ipynb). The result is our original dataframe with additional columns with migration and population data. Note the caveat that we're not working with perfect data here: we don't have data for Yugoslavia, and our data are repeated for the unrecorded years between the five year intervals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "df_VLGM = pd.read_csv('data/migration.csv')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Competition winners\n",
                "\n",
                "Traditionally, the winner of each Eurovision contest becomes the host country for the following year's contest, which is considered to be an expensive operation. This has led to a recurring argument that many countries do not want to win, and therefore put in less effort. At the same time, it has previously been proposed that the number of years since a country's last win influences how likely they are to do well due to how competitive their performance is.\n",
                "\n",
                "In order to investigate this, we calculated how long each performing country had gone without a win in Eurovision. To achieve this, the previous contest winners were gathered from [Wikipedia](https://en.wikipedia.org/wiki/List_of_Eurovision_Song_Contest_winners) and integrated into our existing dataset. We'll skip this step for brevity and pull the data in from the [data collection notebook](https://github.com/KatrionaGoldmann/Eurovision_TDS/blob/story_notebook/eurovision/notebooks/data.ipynb)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "df_VLGMC = pd.read_csv('data/comps_without_win.csv')\n",
                "\n",
                "# Output a sample of the data for 2022, including only some of the more relevant columns\n",
                "df_VLGMC[df_VLGMC['year'] == 2022][['to_country', 'comps_without_win']].sample(5)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Shared border\n",
                "\n",
                "It's been suggested that neighbouring countries may be *more* &mdash; or contrariwise *less* &mdash; likely to vote for one another than countries further away. Is this really the case, and if so, which is it? Or is it just a case of commentator cynicism and *post-hoc* rationalisation?\n",
                "\n",
                "We decided to find out by adding shared borders between countries into our model. We collected these country border data from [GeoDataSource](https://github.com/geodatasource/country-borders/). This only includes land borders, so sea borders are not considered.  For the detailed process of cleaning up and merging the data into our dataset, see the [data collection notebook](https://github.com/KatrionaGoldmann/Eurovision_TDS/blob/story_notebook/eurovision/notebooks/data.ipynb)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# This represents our final dataset for the historical data\n",
                "df = df_VLGMCB = pd.read_csv('data/df_main.csv')\n",
                "\n",
                "# Output a sample of the data including only some of the more relevant columns\n",
                "df_VLGMCB[['from_country', 'to_country', 'has_border']].sample(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "print('Years covered: {} to {}'.format(df['year'].min(), df['year'].max()))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2023 performers\n",
                "\n",
                "Existing data sources have provided data covering all previous years up to 2022. As we noted above, we restrict our data to 1998 onwards so that we can focus on years in which both public and jury voting was used.\n",
                "\n",
                "Our model will make predictions based on the parameters we've provided &mdash; things like the country a performer is from, their gender and the language of the song &mdash; which means that in order to make predictions for 2023, we'll need to know the same characteristics for the 2023 entries. Our model can then use these characteristics in combination with the historical data, to predict the ranking, or scores, of the performances for 2023.\n",
                "\n",
                "The final step in the collection of our data is therefore to find information about the upcoming performances in 2023. These data were gathered from [Wikipedia](https://en.wikipedia.org/wiki/Eurovision_Song_Contest_2023). Some of the parameters for which we weren't able to obtain more recent data &mdash; such as migration numbers &mdash; we repeat the entries from previous years.\n",
                "\n",
                "The code for pulling these data together repeats many of the steps we described earlier for the historical data, and so we won't go through the details again here. You can see the full process in the [data collection notebook](https://github.com/KatrionaGoldmann/Eurovision_TDS/blob/story_notebook/eurovision/notebooks/data.ipynb). As usual we will pull in the results as they were output from that notebook and just review a sample.\n",
                "\n",
                "This gives us all of the data we need. In the next section we'll examine these data and find out what they tell us about Eurovision entries and voting patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "future = pd.read_csv('data/df_2023.csv')\n",
                "\n",
                "# Output a sample of the data including only some of the more relevant columns\n",
                "future[['to_country', 'gender', 'Contains_English', 'Contains_NonEnglish', 'comps_without_win']].sample(5)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exploratory Visualisations\n",
                "\n",
                "Before we start modelling, we explore patterns in the data through summary statistics and visualisations. The aim here is to gain an intuition about trends, relationships between variables, potential quirks and outliers and voting patterns between countries."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Best performing countries\n",
                "\n",
                "Let's first have a look at the winners in each year from 1998 to 2022:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "winners = (df.loc[df['rank'] == 1, ['to_country', 'total_points', 'rank', 'to_code2', 'year']]\n",
                "             .drop_duplicates()\n",
                "             )\n",
                "winners"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Winning Eurovision is hard! Only four countries have managed to win more than once since 1998, and only Ukraine 🇺🇦 and Sweden 🇸🇪  won three times."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "multiple_winners = winners['to_country'].value_counts().loc[lambda x: x > 1]\n",
                "multiple_winners"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Winning is one thing, but which countries perform best _on average_? To make this statistic a bit more robust, we only look at countries that have made the finals at least five times within the timeframe we're considering (see the `count` variable).\n",
                "Over this period, Italy 🇮🇹 has the highest average score, closely followed by Bulgaria 🇧🇬."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "highest_scorers = (df.loc[:, ['to_country', 'to_code2', 'total_points', 'year']]\n",
                "                   .drop_duplicates()\n",
                "                   .groupby('to_country')['total_points']\n",
                "                   .agg(['count', 'mean'])\n",
                "                   .query('count >= 5')\n",
                "                   .round({'mean': 2})\n",
                "                   .sort_values(by='mean', ascending=False)\n",
                "                   .head()\n",
                "                   )\n",
                "highest_scorers"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "While summary statistics like the average can be informative, it would be really interesting to see how well a country is doing over the years in a bit more detail.\n",
                "Are the top performing countries always much better than average, or do a few great perfomances lift up the average scores of these countries?\n",
                "\n",
                "To visualise this for different countries, we create a function to plot the scores of a country over time and mark specific years where the country either didn't perform in the final at all or where it has actually won the competition."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "my_cmap = plt.get_cmap(\"magma_r\")\n",
                "rescale = lambda y: y / 26\n",
                "\n",
                "def plot_country_history(country, ax, df_plot):\n",
                "    df_country_entries = (df_plot\n",
                "                          .loc[df_plot['to_country'] == country]\n",
                "                          .sort_values('year', ascending=False)\n",
                "                          )\n",
                "    country_name = df_country_entries['to_country'].iloc[0].title()\n",
                "\n",
                "    # Add in NaN entries for years where the country did not perform in the finals\n",
                "    present_years = df_country_entries['year'].unique()\n",
                "    absent_years = list(set(range(1998, 2023)) - set(present_years))\n",
                "    df_absent_entries = pd.DataFrame(dict(year=absent_years, total_points=np.nan,\n",
                "                        rank= np.nan, to_country=country))\n",
                "    df_country_entries = pd.concat([df_country_entries, df_absent_entries], ignore_index=True)\n",
                "\n",
                "    # Plot data\n",
                "    ax.bar(df_country_entries['year'], df_country_entries['total_points'],\n",
                "            color=my_cmap(rescale(df_country_entries['rank'])))\n",
                "\n",
                "    # Annotate absent entries, with a special marker for 2020 (cancelled)\n",
                "    for year in absent_years:\n",
                "        marker = \"_\" if year == 2020 else \"x\"\n",
                "        ax.scatter(x=year, y=0.03, s=25, color='grey', marker=marker, transform=ax.get_xaxis_transform())\n",
                "\n",
                "    # Annotate winning entries\n",
                "    winning_entries = df_country_entries.loc[df_country_entries['rank'] == 1, ['year', 'total_points']].drop_duplicates()\n",
                "    if winning_entries.shape[0] > 0:\n",
                "        ax.scatter(x=winning_entries['year'], y=winning_entries['total_points'], s=50, color='gold', marker=\"*\", edgecolor='black', zorder=5)\n",
                "\n",
                "    ax.set_xlim(1997, 2023)\n",
                "    ax.set_title(country_name)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before looking at the top performers, let's first have a look at the United Kingdom 🇬🇧. Every couple of years, the UK has a good year with a top-ten position, but hasn't come first since 1997 with [Katrina and the Waves](https://www.youtube.com/watch?v=azw4Kh8Rqpw) (not in our dataset). 2022 was the most successful year since then, with Sam Ryder becoming second with the song [Space Man](https://www.youtube.com/watch?v=RZ0hqX_92zI)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "fig, ax = plt.subplots(1, 1, figsize=(5, 4), sharey=True, sharex=True, squeeze=True)\n",
                "\n",
                "plot_country_history('united kingdom', ax, df)\n",
                "\n",
                "legend_elements = [Line2D([0], [0], marker='*', color='white', label='Winner',\n",
                "                          markerfacecolor='gold', markersize=12, markeredgecolor='black'),                          \n",
                "                  Line2D([0], [0], marker='x', color='white', label='Did not perform in final',\n",
                "                          markerfacecolor='grey', markersize=8, markeredgecolor='grey'), \n",
                "                  Line2D([0], [0], marker='_', color='white', label='Competition cancelled',\n",
                "                          markerfacecolor='grey', markersize=8, markeredgecolor='grey')]\n",
                "fig.legend(handles=legend_elements, loc='right', ncol=1, bbox_to_anchor=(0.9, -0.05))\n",
                "\n",
                "sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.Normalize(vmin=1, vmax=26))\n",
                "cbaxes = fig.add_axes([0.2, -0.05, 0.2, 0.05]) # x y deltax deltay\n",
                "\n",
                "fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.02, pad=0.1, label='Position', \n",
                "             cax = cbaxes)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compared to the UK, how do the _most successful_ countries perform over the years? We'll have a look at the top four countries, for both the total and the average scores."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "fig = plt.figure(layout='constrained', figsize=(12, 6))\n",
                "subfigs = fig.subfigures(2, 1, wspace=0.1)\n",
                "\n",
                "for subfig, country_group, title in zip(subfigs,\n",
                "                                        [multiple_winners, highest_scorers],\n",
                "                                        ['Multiple winners', 'Countries with highest average points']\n",
                "                                        ):\n",
                "    axs = subfig.subplots(1, 4, sharey=True, sharex=True, squeeze=True)\n",
                "    subfig.suptitle(title, fontsize=14, fontweight='bold')\n",
                "    for i, country in enumerate(country_group.index[:4]): \n",
                "        plot_country_history(country, axs[i], df)\n",
                "\n",
                "# Add in colorbar and legend\n",
                "sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.Normalize(vmin=1, vmax=26))\n",
                "cbaxes = fig.add_axes([0.3, -0.08, 0.2, 0.05]) # x y deltax deltay\n",
                "fig.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.02, pad=0.1, label='Position', cax=cbaxes)\n",
                "fig.legend(handles=legend_elements, loc='right', ncol=1, bbox_to_anchor=(0.7, -0.08))\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There's a clear difference to the picture of the UK here.\n",
                "Ukraine 🇺🇦 and Sweden 🇸🇪 have not only won three times each, but have also placed within the top ten many times over the years (indicated by the lighter bars).\n",
                "Some countries haven't participated very often, but have done really well the few times they did, such as Bulgaria 🇧🇬.\n",
                "This is reflected in their second-place ranking in the table of average scores."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Voting patterns between country pairs"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There is a lot more to explore in the Eurovision data.\n",
                "Countries are performing but are also voting for each other.\n",
                "Do countries mainly vote for the actual performance or are the some general biases between countries?\n",
                "To dig deeper into this, we'll explore voting patterns between country pairs.\n",
                "\n",
                "We start by calculating the score each country has given to each other country, averaged over all years."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_voting = (df.loc[:, ['from_country', 'points', 'to_country', 'year']]\n",
                "               .assign(average_vote=lambda x: x.groupby(['to_country', 'from_country'])['points'].transform('mean'))\n",
                "               .drop_duplicates(subset=['from_country', 'to_country'])\n",
                "               .loc[:, ['from_country', 'to_country', 'average_vote']]\n",
                "               .pivot(index='from_country', columns='to_country', values='average_vote')\n",
                "               )\n",
                "df_voting.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can plot a *heatmap* to illustrate this data.\n",
                "In this color scheme we have chosen, darker squares indicate a *larger* average vote given by one country to another."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "import scipy.spatial as sp\n",
                "import scipy.cluster.hierarchy as hc\n",
                "\n",
                "def plot_voting_heatmap(df_heatmap, cmap, suptitle, center=None):\n",
                "    # Reindex rows to be in the same order as columns\n",
                "    df_heatmap = df_heatmap.reindex(df_heatmap.columns)\n",
                "\n",
                "    row_dism = 1 - df_heatmap.T.corr()\n",
                "    row_linkage = hc.linkage(sp.distance.squareform(row_dism), method='complete')\n",
                "    plot = sns.clustermap(df_heatmap, row_linkage=row_linkage, col_linkage=row_linkage, \n",
                "                          figsize=(9, 8),\n",
                "                          mask=df_heatmap.isnull(), \n",
                "                          dendrogram_ratio=[0.15, 0.01],\n",
                "                          cbar_pos=(0.8, 1.01, 0.1, 0.019),\n",
                "                          cbar_kws={'orientation': 'horizontal'},\n",
                "                          cmap=cmap, \n",
                "                          xticklabels=1,\n",
                "                          yticklabels=1,\n",
                "                          **{'center': center} if center is not None else {})\n",
                "    plot.ax_col_dendrogram.set_visible(False) \n",
                "\n",
                "    plot.fig.suptitle(suptitle, fontsize=16, y=1.02)\n",
                "    plot.ax_heatmap.set_xlabel('Performing country')\n",
                "    plot.ax_heatmap.set_ylabel('Voting country')\n",
                "    plot.ax_heatmap.tick_params(axis='both', which='major', labelsize=9)\n",
                "    plot.ax_heatmap.xaxis.tick_bottom()   # otherwise x-axis ticks disappear, see: mwaskom/seaborn#2305\n",
                "    return plot\n",
                "\n",
                "plot_voting_heatmap(df_voting, cmap='magma_r', suptitle='Average score given to performing countries')\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this plot, countries are grouped using hierarchical clustering, ordering countries with similar voting patterns together. \n",
                "\n",
                "From here, we can see a few patterns emerging.\n",
                "Some countries tend to vote higher for each other, forming darker squares in the heatmap.\n",
                "One such square in the bottom right is around Slovenia 🇸🇮, Bosnia and Herzegovina 🇧🇦, Croatia 🇭🇷, and Serbia 🇷🇸, which all give each other relatively high votes on average.\n",
                "\n",
                "However, the *votes* alone don't say that much.\n",
                "As we've already seen, some countries simply tend to perform well at Eurovision; this would naturally make their average received scores larger!\n",
                "To extract this factor from the analysis, so that we can look into potential country-pair voting biases, we therefore look for *deviations* from a country's average performance score.\n",
                "Essentially, we are asking whether a certain country gives higher or lower votes to another country, compared to all other countries.\n",
                "\n",
                "We start by calculating the voting deviations from the mean each country receives. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_voting_deviation = (df.loc[:, ['from_country', 'points', 'to_country', 'year']]\n",
                "                          # This is the average vote from one country to another, the same as above.\n",
                "                         .assign(average_vote=lambda x: x.groupby(['to_country', 'from_country'])['points'].transform('mean'))\n",
                "                          # This is the average vote received by one country from all others.\n",
                "                         .assign(average_votes_all=lambda x: x.groupby(['to_country'])['points'].transform('mean'))\n",
                "                          # Calculate the deviation from the mean.\n",
                "                         .assign(vote_deviation=lambda x: x['average_vote'] - x['average_votes_all'])\n",
                "                          # We drop any voter-performer pairs for which there are fewer than three votes, as this is likely\n",
                "                          # not representative of the country's true voting pattern.\n",
                "                         .assign(count=lambda x: x.groupby(['from_country', 'to_country'])['vote_deviation'].transform('count'))\n",
                "                         .query('count >= 3')\n",
                "                         .drop_duplicates(subset=['from_country', 'to_country'])\n",
                "                         .loc[:, ['from_country', 'to_country', 'vote_deviation']]\n",
                "                         .pivot(index='from_country', columns='to_country', values='vote_deviation')\n",
                "                         )\n",
                "df_voting_deviation.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now plot the same heatmap, but with the deviations instead of the actual votes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "plot = plot_voting_heatmap(df_voting_deviation, cmap='RdBu_r',\n",
                "                           suptitle='Average vote deviation from one country to another',\n",
                "                           center=0)\n",
                "\n",
                "from matplotlib.patches import Rectangle\n",
                "\n",
                "# Plot a box around the given entries, as specified by indices\n",
                "def highlight(xmin, ymin, dx, dy, color):\n",
                "    plot.ax_heatmap.add_patch(Rectangle((xmin, ymin), dx, dy, fill=False, edgecolor=color, linewidth=2))\n",
                "    # Plot the reverse as well, plus a connecting line, if the box is not symmetric about the diagonal\n",
                "    if xmin != ymin or dx != dy:\n",
                "        plot.ax_heatmap.add_patch(Rectangle((ymin, xmin), dy, dx, fill=False, edgecolor=color, linewidth=2))\n",
                "        plot.ax_heatmap.plot([xmin+dx, ymin], [ymin, xmin+dx], color=color, linewidth=1, linestyle='--')\n",
                "\n",
                "highlight(4, 4, 9, 9, 'black')                # ex-Soviet\n",
                "highlight(31, 31, 13, 13, 'black')            # Baltics\n",
                "highlight(13, 13, 7, 7, 'black')              # Balkans\n",
                "\n",
                "highlight(0, 27, 1, 4, 'cornflowerblue')      # Turkey to Germany, the Netherlands, Belgium, France\n",
                "highlight(20, 25, 4, 1, 'darkcyan')           # Italy to Malta, San Marino, Albania, Portugal\n",
                "highlight(13, 38, 1, 1, 'indigo')             # Serbia to Hungary\n",
                "highlight(17, 21, 1, 1, 'lightseagreen')      # North Macedonia to Albania\n",
                "highlight(23, 30, 1, 1, 'goldenrod')          # Portugal to France\n",
                "highlight(1, 3, 1, 1, 'fuchsia')              # Greece to Cyprus\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here, the colorscheme chosen assigns blue to negative deviations (i.e. a voting country gives lower-than-average votes to a performing country), and red to positive deviations.\n",
                "\n",
                "There do not appear to be any significant *negative* deviations.\n",
                "However, there are a number of interesting regions with positive deviations, which are highlighted by additional coloured boxes.\n",
                "For example:\n",
                "\n",
                "- The small blue boxes on the left indicate that Turkey's entries have consistently obtained higher-than-average scores from Germany, the Netherlands, Belgium, and France; but that this isn't reciprocated, as the other blue box on the top shows.\n",
                "  A possible hypothesis for this may be the fact that there is a significant Turkish diaspora in these countries; this reinforces our decision to include migration statistics in our collated dataset.\n",
                "\n",
                "- The large black boxes along the diagonal show clusters of countries who vote highly for each other and tend to be closer geographically.\n",
                "  For example, the cluster in the bottom-right contains many Nordic countries, the box in the centre Balkan countries, and the top-left box ex-Soviet countries.\n",
                "  Overall, this suggests that sharing a border and and other geopolitical relationships may influence how countries vote."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Voting Pair Plots"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also look at these inter-country relationships using scatter plots.\n",
                "In the following plots, each point is an average voting score from one country to another."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "pair_grouped_points = df.groupby(['to_country', 'from_country'])['points']\n",
                "\n",
                "votes = (df.loc[:, ['to_country', 'from_country', 'points', 'year']]\n",
                "            .assign(\n",
                "                # Number of times the country performed in Eurovision finals\n",
                "                times_competed=lambda x: x.groupby(['to_country'])['year'].transform('nunique'),\n",
                "                # The total number of points country A has given to country B, across all years\n",
                "                total_points=pair_grouped_points.transform('sum'),\n",
                "                # The number of times country A has given (nonzero) points to country B, across all years\n",
                "                times_voted=pair_grouped_points.transform(lambda x: x[x > 0].count()),\n",
                "                # The average number of points country A has given to country B, across all years\n",
                "                average_points=pair_grouped_points.transform('mean'),\n",
                "                # The average number of points country B has gotten, across all voting countries and all years\n",
                "                overall_average_points=lambda x: x.groupby(['to_country'])['points'].transform('mean'),\n",
                "                # The deviation from the average points given by country A to country B\n",
                "                vote_deviation=lambda x: x['average_points'] - x['overall_average_points'])\n",
                "            .loc[:, ['to_country', 'from_country', 'times_competed', 'times_voted', 'total_points', 'average_points', 'overall_average_points', 'vote_deviation']]\n",
                "            .drop_duplicates(subset=['to_country', 'from_country'])\n",
                "            .sort_values(by=['to_country', 'from_country'])\n",
                "            .reset_index(drop=True)\n",
                ")\n",
                "votes.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The following is an *interactive* scatter plot, which will allow you to better explore the data yourself.\n",
                "Each data point represents one performer–voter pair; hovering over it will show specific information about each pair.\n",
                "\n",
                "The *x*-axis represents the total number of points which the voter has given the performer over the timeframe of our analysis, and the *y*-axis the average.\n",
                "Thus, for example, the upper-left corner contains country pairs which have not voted many times (leading to a small total), but with a large average (meaning that very high scores have been given on average).\n",
                "The top-leftmost point reveals that Serbia 🇷🇸 has only voted for Montenegro 🇲🇪 once, but gave them 12 points, the highest possible score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "import plotly.express as px\n",
                "\n",
                "# The following lines are needed for Quarto to render the interactive plot\n",
                "import plotly.io as pio\n",
                "pio.renderers.default = \"plotly_mimetype+notebook_connected\"\n",
                "\n",
                "fig = px.scatter(votes, x='total_points', y='average_points')\n",
                "fig.update_traces(hovertemplate=('Performer: %{customdata[0]}'\n",
                "                                 '<br>Voter: %{customdata[1]}'\n",
                "                                 '<br>Total Eurovisions competed: %{customdata[2]}'\n",
                "                                 '<br>Total times voted for by selected country: %{customdata[3]}'\n",
                "                                 '<br>Total points given: %{customdata[4]}'\n",
                "                                 '<br>Average points: %{customdata[5]:.2f}'),\n",
                "                  customdata=votes,\n",
                "                  marker={'color': 'rgba(50, 50, 150, 0.1)', 'opacity': 0.5, 'size': 6,\n",
                "                          'line': {'color': 'rgba(50, 50, 150, 1.0)', 'width': 1}})\n",
                "fig.update_layout(hoverlabel_align='left', width=640, height=640, margin=dict(l=20, r=20, t=20, b=20),\n",
                "                  xaxis={'title': 'Total points given by one country to another'},\n",
                "                  yaxis={'title': 'Average points given by one country to another'})\n",
                "fig.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Alternatively, we can visualise the vote deviations for each performer–voter pair as we did above.\n",
                "We reuse the same colour scheme here, with red implying a strong positive preference (i.e. a country that consistently gave higher-than-average votes to another) and blue indicating a negative preference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "votes = (votes.assign(highest_average_point=lambda x: x.groupby(['to_country'])['average_points'].transform('max'))\n",
                "              .sort_values(by='highest_average_point', ascending=True))\n",
                "\n",
                "fig = px.scatter(votes, x='average_points', y='to_country', color='vote_deviation', \n",
                "                 color_continuous_scale=px.colors.diverging.RdBu_r,\n",
                "                 color_continuous_midpoint=0)\n",
                "fig.update_traces(hovertemplate=('Performer: %{customdata[0]}'\n",
                "                                 '<br>Voter: %{customdata[1]}'\n",
                "                                 '<br>Total Eurovisions competed: %{customdata[2]}'\n",
                "                                 '<br>Total times voted for by selected country: %{customdata[3]}'\n",
                "                                 '<br>Total points given: %{customdata[4]}'\n",
                "                                 '<br>Average points overall: %{customdata[7]:.2f}'),\n",
                "                  customdata=votes)\n",
                "fig.update_layout(hoverlabel_align='left', width=640, height=640, margin=dict(l=20, r=20, t=20, b=20),\n",
                "                  xaxis={'title': 'Average points received from each voter'},\n",
                "                  yaxis={'title': 'Performing country'}, \n",
                "                  coloraxis_colorbar=dict(title='Deviation from average points'))\n",
                "\n",
                "fig.update_yaxes(tickfont_size=8)\n",
                "fig.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploring Country Friendships, Biases, and One-sided Relationships"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After looking at the broader patterns above, let's now dive into some specific country-pairs. \n",
                "We will look for the top country pairs which\n",
                "\n",
                "- give each other very high scores\n",
                "- give each other very low scores\n",
                "- have a one-sided relationship, where one country gives high scores to another, but receives low scores back."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To look at more specific relationships, we'll calculate for each country pair the difference between their average votes for each other.\n",
                "This value would be small if they both tend to give each other high or low scores, but it would be large if one country gives the other high scores, but gets low scores back.\n",
                "To ensure that our analysis is robust, we exclude any pairs who have not voted for each other at least 5 times (in both directions)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# Remove the countries above, then group by performer and voter, calculate mean votes and count number of years\n",
                "df_pairs = (df\n",
                "    .groupby(['from_country', 'to_country'])\n",
                "    .agg(votes = ('points', 'mean'), num_years = ('year', 'count'))\n",
                "    .reset_index()\n",
                "    .sort_values(by='votes', ascending=False)\n",
                ")\n",
                "\n",
                "# Merge original dataframe with its reverse\n",
                "swapped = (df_pairs.rename(columns={'from_country': 'to_country', 'to_country': 'from_country'})\n",
                "    .loc[:, ['from_country', 'to_country', 'votes', 'num_years']]\n",
                ")\n",
                "df_pairs = (df_pairs.merge(swapped, on=['from_country', 'to_country'])\n",
                "    .drop_duplicates()\n",
                "    .query('from_country != to_country and num_years_x >= 5 and num_years_y >= 5')\n",
                "    .assign(votes_diff = lambda x: abs(x['votes_x'] - x['votes_y']))\n",
                ")\n",
                "\n",
                "# create combined column with pairs in alphabetical order\n",
                "df_pairs['country_pair'] = df_pairs[['from_country', 'to_country']].apply(lambda x: ' - '.join(sorted(x)), axis=1)\n",
                "# Remove duplicate country pairs and the temporary country_pair column\n",
                "df_pairs = (df_pairs\n",
                "    .drop_duplicates(subset=['country_pair'])\n",
                "    .drop(columns=['country_pair'])\n",
                "    .loc[:, ['from_country', 'to_country', 'votes_x', 'votes_y', 'votes_diff']]\n",
                ")\n",
                "\n",
                "df_pairs.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To prepare the data for plotting, we filter for the top five country pairs that give each other high, low and unequal votes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# Number of country pairs to show for each category\n",
                "N = 5\n",
                "\n",
                "# top 5 country pairs with high votes for each other\n",
                "top_highs = (df_pairs\n",
                "    .query('votes_diff < 3')\n",
                "    .sort_values('votes_x', ascending=False)\n",
                "    .head(N)\n",
                "    .assign(group='high')\n",
                ")\n",
                "\n",
                "# top 5 country pairs with low votes for each other\n",
                "top_lows = (df_pairs\n",
                "    .query('votes_diff < 3')\n",
                "    .sort_values('votes_x', ascending=True)\n",
                "    .head(N)\n",
                "    .assign(group='low')\n",
                ")\n",
                "\n",
                "# top 5 unbalanced country pairs (one gives high votes to the other, but gets low votes back)\n",
                "top_one_sided = (df_pairs\n",
                "    .sort_values('votes_diff', ascending=False)\n",
                "    .head(N)\n",
                "    .assign(group='one-sided')\n",
                ")\n",
                "\n",
                "# combine \n",
                "top_relationships = pd.concat([top_highs, top_lows, top_one_sided])\n",
                "top_relationships = top_relationships.sort_values(['group', 'votes_x'])\n",
                "top_relationships"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# Replace group names with numeric values for sorting\n",
                "group_order = {'low': 1, 'one-sided': 2, 'high': 3}\n",
                "top_relationships['group_order'] = top_relationships['group'].replace(group_order)\n",
                "\n",
                "# Create a new column representing the minimum value between 'votes_x' and 'votes_y'\n",
                "top_relationships['min_votes'] = top_relationships[['votes_x', 'votes_y']].min(axis=1)\n",
                "\n",
                "# Sort the DataFrame by 'group_order' and 'min_votes'\n",
                "top_relationships = (top_relationships\n",
                "    .sort_values(by=['group_order', 'min_votes'])\n",
                "    .reset_index(drop=True)\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot the results!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "import matplotlib.colors as mcolors\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "ax.grid(axis='x', linestyle='-', linewidth=0.5)\n",
                "\n",
                "# create a color map with 6 colors from red to blue\n",
                "colors = sns.color_palette(\"YlOrRd\", 6)[::-1]\n",
                "cmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", colors, N=len(colors))\n",
                "\n",
                "# get color map with viridis colors for 6 bins\n",
                "cmap = plt.get_cmap('viridis' )\n",
                "\n",
                "colors = [\"#d53e4f\", \"#e6f598\", \"#abdda4\", \"#66c2a5\", \"#3288bd\", \"#5e4fa2\"]\n",
                "cmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", colors, N=len(colors))\n",
                "\n",
                "# define the range boundaries\n",
                "bins = np.arange(0, 13, 2)\n",
                "\n",
                "# add text labels and points\n",
                "text_offset = 0.2\n",
                "for i, row in top_relationships.iterrows():\n",
                "    ax.text(x=row['votes_x'] + text_offset, y=i, s=row['to_country'],\n",
                "            ha='left', va='center', fontsize=14)\n",
                "    ax.text(x=row['votes_y'] - text_offset, y=i, s=row['from_country'],\n",
                "            ha='right', va='center', fontsize=14)\n",
                "\n",
                "    # plot points with colors based on x-value range\n",
                "    x_color = np.digitize(row['votes_x'], bins=bins, right=True) - 1\n",
                "    y_color = np.digitize(row['votes_y'], bins=bins, right=True) - 1\n",
                "    ax.scatter(row['votes_x'], i, color=cmap(x_color / 6), s=100, alpha=1, zorder=3)\n",
                "    ax.scatter(row['votes_y'], i, color=cmap(y_color / 6), s=100, alpha=1, zorder=3)\n",
                "\n",
                "    # add line between countries with slightly shortened length\n",
                "    line_buffer = 0.1\n",
                "    ax.hlines(y=i, xmin=row['votes_x'] + line_buffer, xmax=row['votes_y'] - line_buffer,\n",
                "              color='black', alpha=0.7, zorder=2, linewidth=0.7)\n",
                "\n",
                "ax.set_xlabel('Average received vote of a country from its paired country', fontsize=14)\n",
                "ax.set_ylabel('')\n",
                "\n",
                "# Hide the y axis\n",
                "ax.get_yaxis().set_visible(False)\n",
                "ax.spines[['top', 'right', 'left']].set_visible(False)\n",
                "\n",
                "# Add legend\n",
                "markers = [plt.Line2D([0, 0], [0, 0],\n",
                "                      color=cmap(i / 6), marker='o', linestyle='') for i in range(6)]\n",
                "plt.legend(markers, ['{}-{}'.format(i, i + 2) for i in bins[:-1]],\n",
                "           numpoints=1, loc='lower right', title='Vote ranges')\n",
                "\n",
                "plt.title('Country pairs with high, low, and unequal votes for each other', fontsize=18,  loc='center', pad=15)\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The figure shows the top five country pairs which give each other high, low and unequal scores.\n",
                "The point next to a country name is the score it *received* from the other country. For example, in line with the previous figures, both France 🇫🇷 and Germany 🇩🇪 on average receive low scores from Turkey 🇹🇷, but vote highly for Turkey.\n",
                "Cyprus 🇨🇾  and Greece 🇬🇷  give each other high scores, and Albania 🇦🇱 and Lithuania 🇱🇹 tend to give each other low scores.\n",
                "\n",
                "The plot differs a bit from the results above, because it is looking at raw votes, not deviations from the mean vote.\n",
                "Therefore, one-sided voting does not necessarily indicate bias in voting: it may simply be because the country has historically performed very well (or very poorly!) in the Eurovision Song Contest."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Migration Data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "One of our main goals was to predict the winner of the 2023 contest.\n",
                "On a finer scale, this means predicting how each country will vote for each other country; and it is conceivable that countries which contain large immigrant communities from another country might give more favourable scores to that country.\n",
                "\n",
                "To test this hypothesis, we incorporated migration data from [Our World in Data](https://ourworldindata.org/migration) into our models.\n",
                "In the discussion which follows, `v2p` refers to migration from a voting country to a performing country, and `p2v` the reverse.\n",
                "The `migration_...` columns are absolute numbers of immigrants; `prop_emigrants` are the proportion of migrants with respect to the total population of the country receiving them.\n",
                "\n",
                "Thus, in the first row of the table that follows, there were 205 migrants from Belgium to Croatia in 1998, which formed 0.0044% of Croatia's population."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_migration = df.filter(['from_country', 'from_code2',\n",
                "                          'to_country', 'to_code2',\n",
                "                          'year',  'points',\n",
                "                          'migration_v2p', 'prop_emigrants_v2p',\n",
                "                          'migration_p2v', 'prop_emigrants_p2v'])\n",
                "df_migration.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As a measure of bias, we measure how much a given score deviates from the average score the country received in that year.\n",
                "Thus, for example, if in a given year the UK received an average of 2 points from every country but got 5 points from Australia, the *score deviation* from Australia to UK would be +3 for that year.\n",
                "\n",
                "We begin by plotting the score deviation against the proportion of emigrants in both directions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate score deviation per year\n",
                "df_migration['avg_votes'] = df_migration.groupby(['to_code2', 'year'])['points'].transform('mean')\n",
                "df_migration['deviation'] = df_migration['points'] - df_migration['avg_votes']\n",
                "\n",
                "fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(10, 4))\n",
                "\n",
                "for (ax, col_name) in zip(axs, ['prop_emigrants_v2p', 'prop_emigrants_p2v']):\n",
                "    df_migration_temp = df_migration.dropna(subset=[col_name])\n",
                "    sns.regplot(x=col_name, y='deviation', data=df_migration_temp, ax=ax)\n",
                "    reg = scipy.stats.linregress(df_migration_temp[col_name],\n",
                "                                 df_migration_temp['deviation'])\n",
                "\n",
                "    sign = '+' if reg.intercept > 0 else '-'\n",
                "    ax.set(xlabel=col_name, ylabel='Score deviation',\n",
                "           title=rf'$y = {reg.slope:.2f}x {sign} {np.abs(reg.intercept):.2f}$ ($R^2 = {reg.rvalue ** 2:.2f}$)')\n",
                "    ax.axhline(y=0, color='black', linewidth=2)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "(Note that the *x*-axes on these two plots are very different.)\n",
                "Clearly, there is no strong link between migration and voting.\n",
                "This may, however, be largely explained by the majority of data points where there is simply not much migration going on.\n",
                "One could easily argue that in such cases, it is almost impossible for migrants to have any significant impact on (for example) televoting.\n",
                "\n",
                "If we perform the analysis but this time restrict it to countries for which `prop_emigrants_...` is larger than 0.1 (i.e. 10%), then we get a somewhat stronger effect, especially for the `p2v` graph on the right:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(10, 4))\n",
                "\n",
                "for (ax, col_name) in zip(axs, ['prop_emigrants_v2p', 'prop_emigrants_p2v']):\n",
                "    df_migration_temp = (df_migration\n",
                "        .dropna(subset=[col_name])\n",
                "        .query(f'{col_name} > 0.1')\n",
                "    )\n",
                "    sns.regplot(x=col_name, y='deviation', data=df_migration_temp, ax=ax)\n",
                "    reg = scipy.stats.linregress(df_migration_temp[col_name],\n",
                "                                 df_migration_temp['deviation'])\n",
                "\n",
                "    sign = '+' if reg.intercept > 0 else '-'\n",
                "    ax.set(xlabel=f'{col_name} > 0.1', ylabel='Score deviation',\n",
                "           title=rf'$y = {reg.slope:.2f}x {sign} {np.abs(reg.intercept):.2f}$ ($R^2 = {reg.rvalue ** 2:.2f}$)')\n",
                "    ax.axhline(y=0, color='black', linewidth=2)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There is definitely still a large amount of noise in this analysis, and it is impossible to suggest any causal link between migration and scores: for example, do migrants (in voting countries) genuinely tend to vote for their home (performing) countries, or is it simply that countries which are geopolitically closer tend to have larger migration numbers anyway?\n",
                "Nevertheless, it appears that keeping the migration data in as a potential explanatory variable for our models would be useful."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Language Data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**TODO** Get language data cleaned up, see https://github.com/KatrionaGoldmann/Eurovision_TDS/blob/issue-5-exploratory_visualisations/eurovision/notebooks/language_visualistaions.ipynb.\n",
                "\n",
                "**TODO** Discussion of Eurovision language rules (this has changed over time).\n",
                "\n",
                "For our analysis of song language, we were interested in several aspects which may influence voting:\n",
                "\n",
                "1. whether the song contained any English lyrics;\n",
                "1. whether the performer sings in their official language;\n",
                "1. the total number of languages appearing in the song (can you hedge your bets?); and\n",
                "1. whether a song sung in a given language garners more votes from countries which have that language as one of their official languages.\n",
                "\n",
                "Consequently, in our dataset, we have classified the *song language* into the following categories: the country's official language (`own`), English (`eng`), or an entirely separate language (`other`).\n",
                "When English *is* one of the country's official languages, both `own` and `other` are selected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "df_performance = (df.loc[:, ['year', 'Artist', 'to_country', 'total_points', 'rank', 'to_code2',\n",
                "                             'Official_languages', 'Language_sung', 'Contains_English',\n",
                "                             'Contains_NonEnglish', 'Contains_Multiple_Languages',\n",
                "                             'Number_of_Languages', 'Contains_Own_Language', 'gender']]\n",
                "                    .drop_duplicates()\n",
                "                    .assign(English_only = lambda x: (x['Contains_English']) & (x['Number_of_Languages'] == 1),\n",
                "                            No_English = lambda x: ~x['Contains_English'],\n",
                "                            Some_English = lambda x: (x['Contains_English']) & (x['Number_of_Languages'] > 1))\n",
                ")\n",
                "df_performance.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can start by investigating how often a country is likely to sing in English:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "df_language = (df_performance\n",
                "    .groupby('to_country')\n",
                "    .agg({'English_only': 'mean', 'Some_English': 'mean', 'No_English': 'mean'})\n",
                "    .sort_values(by=['English_only', 'Some_English'], ascending=True)\n",
                ")\n",
                "\n",
                "colours = {'English_only': 'royalblue', 'No_English': 'seagreen', 'Some_English': 'goldenrod'}\n",
                "\n",
                "df_language.plot(kind='bar', figsize=(15, 6), stacked=True, color=colours)\n",
                "\n",
                "plt.legend(['English only', 'Partly English', 'No English'], title=\"Performance languages\", loc=[1, 1], \n",
                "           fontsize=14,  bbox_to_anchor=(0.51, 0., 0.5, 0.5), title_fontsize=16)\n",
                "\n",
                "plt.title('How frequently countries sing in English', fontsize=20, pad=30)\n",
                "\n",
                "plt.text(df_language.shape[0] - 1, 1.1, 'Countries more likely to sing in English →',\n",
                "         ha='right', va='center', fontsize=14)\n",
                "plt.text(0.05, 1.1, '← Countries less likely to sing in English ',\n",
                "         ha='left', va='center',  fontsize=14)\n",
                "plt.xticks(rotation=-45, ha='left')\n",
                "plt.xlabel('')\n",
                "plt.ylabel('Ratio of performances')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "TODO: Text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "from statannot import add_stat_annotation\n",
                "\n",
                "# convert wide to long format\n",
                "df_long = df_performance[['English_only', 'No_English',\t'Some_English', 'total_points']]\n",
                "df_long = df_long.melt(id_vars=['total_points'], var_name='language', value_name='contains_language')\n",
                "df_long['contains_language'] = df_long['contains_language'].astype(int)\n",
                "\n",
                "# boxplots for each language type\n",
                "ax = sns.boxplot(x='language', y='total_points', \n",
                "    data=df_long.loc[df_long['contains_language'] > 0], \n",
                "    palette=colours, showfliers=False, \n",
                "    order=['English_only', 'Some_English', 'No_English'])\n",
                "sns.stripplot(x='language', y='total_points', \n",
                "    order=['English_only', 'Some_English', 'No_English'],\n",
                "    data=df_long.loc[df_long['contains_language'] > 0], \n",
                "    jitter=0.25, size=2, color=\".3\", linewidth=0)\n",
                "\n",
                "plt.title('Average points for performances in different languages', fontsize=20, pad=30)\n",
                "plt.xlabel('')\n",
                "plt.ylabel('Total points')\n",
                "\n",
                "add_stat_annotation(ax, data=df_long.loc[df_long['contains_language'] > 0],\n",
                "                    x='language', y='total_points', \n",
                "                    order=['English_only', 'Some_English', 'No_English'],\n",
                "                    box_pairs=[(\"English_only\", \"No_English\")],\n",
                "                    test='Mann-Whitney', text_format='star', verbose=0)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can perform a similar analysis, but for a country's *own* language instead of English.\n",
                "Typically, those countries on the left of this plot are those who do sing in English but for which English is not their official language.\n",
                "Those on the right are countries who sing in their official language exclusively."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "df_language = (df_performance\n",
                "    .assign(Own_language = lambda x: x['Contains_Own_Language'],\n",
                "            Other_language = lambda x: ~x['Contains_Own_Language'])\n",
                "    .groupby('to_country')\n",
                "    .agg({'Other_language': 'mean', 'Own_language': 'mean'})\n",
                "    .sort_values(by=['Own_language', 'Other_language'], ascending=True)\n",
                ")\n",
                "\n",
                "df_language.plot(kind='bar', figsize=(15, 6), stacked=True,\n",
                "                 color={'Own_language': 'teal', 'Other_language': 'lightsteelblue'})\n",
                "\n",
                "plt.legend(['Other language', 'Own language'], title=\"Performance languages\", loc=[1, 1], \n",
                "        fontsize=14,  bbox_to_anchor=(0.51, 0., 0.5, 0.5), title_fontsize=16)\n",
                "plt.title('How frequently countries sing in their official languages', fontsize=20, pad=30)\n",
                "plt.text(df_language.shape[0] - 1, 1.1, 'Countries more likely to sing in their official language →',\n",
                "         ha='right', va='center', fontsize=14)\n",
                "plt.text(0.05, 1.1, '← Countries less likely to sing in their official language',\n",
                "         ha='left', va='center',  fontsize=14)\n",
                "plt.xticks(rotation=-45, ha='left')\n",
                "plt.xlabel('')\n",
                "plt.ylabel('Ratio of performances')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "TODO: Text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "sns.boxplot(x='Number_of_Languages', y='total_points', data=df_performance, showfliers=False)\n",
                "sns.stripplot(x='Number_of_Languages', y='total_points', data=df_performance, jitter=0.25, size=2, color=\".3\", linewidth=0)\n",
                "\n",
                "plt.title('Points Scored by Number of Languages appearing in Song', fontsize=20, pad=30)\n",
                "plt.xlabel('Number of Languages')\n",
                "plt.ylabel('Total points')\n",
                "\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "TODO: Text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# violin plot\n",
                "sns.violinplot(x='Contains_Voting_Language', y='points', data=df, inner=None, color=\"cornflowerblue\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Gender Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "from matplotlib.colors import to_rgba\n",
                "\n",
                "gender_df = df[['year', 'to_country', 'gender']].copy().drop_duplicates()\n",
                "\n",
                "countries = gender_df.sort_values(by=['to_country'])['to_country'].drop_duplicates().to_list()\n",
                "years = gender_df['year'].drop_duplicates().to_list()\n",
                "\n",
                "gender_colours = {\n",
                "    'female': to_rgba('seagreen'),\n",
                "    'group': to_rgba('wheat'),\n",
                "    'male': to_rgba('indianred'),\n",
                "    'none': to_rgba('white')\n",
                "}\n",
                "\n",
                "gender = []\n",
                "for year in years:\n",
                "    missing = pd.DataFrame({'year': [year] * len(countries), 'to_country': countries, 'gender': ['none'] * len(countries)}).set_index('to_country')\n",
                "    missing.update(gender_df[gender_df['year'] == year].set_index('to_country'))\n",
                "    gender.append(list(map(lambda x: gender_colours[x], missing.sort_values(by=['to_country'])['gender'].to_list())))\n",
                "\n",
                "gender = list(map(list, zip(*gender)))\n",
                "fig, ax = plt.subplots(1, 1)\n",
                "fig.set_size_inches(10, 10)\n",
                "img = plt.imshow(gender, aspect=0.7)\n",
                "ax.set_xticks(range(len(years)))\n",
                "ax.set_xticklabels(years)\n",
                "plt.xticks(rotation=90)\n",
                "ax.set_yticks(range(len(countries)))\n",
                "ax.set_yticklabels(list(map(str.title, countries)))\n",
                "ax.grid(False)\n",
                "plt.title('Gender of Artists at Eurovision by Year and Performing Country\\n(countries ordered alphabetically)')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "for gender in ['female', 'male', 'group']:\n",
                "    count = len(gender_df[gender_df['gender'] == gender])\n",
                "    print('Total {} performers: {} ({:.0%})'.format(gender, count, count/len(gender_df)))\n",
                "\n",
                "def ratio(gender, x): return len([a for a in x if a == gender]) / len(x)\n",
                "\n",
                "gender_df = gender_df.groupby('to_country').agg(\n",
                "    female=pd.NamedAgg(column='gender', aggfunc=lambda x: ratio('female', x)),\n",
                "    group=pd.NamedAgg(column='gender', aggfunc=lambda x: ratio('group', x)),\n",
                "    male=pd.NamedAgg(column='gender', aggfunc=lambda x: ratio('male', x)),\n",
                ")\n",
                "gender_df = gender_df.sort_values(by=['female', 'group'], ascending=False)\n",
                "\n",
                "gender_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "gender_colours = {\n",
                "    'female': to_rgba('seagreen'),\n",
                "    'group': to_rgba('wheat'),\n",
                "    'male': to_rgba('indianred')#,\n",
                "    #'none': to_rgba('white')\n",
                "}\n",
                "\n",
                "gender_df[gender_colours.keys()].plot(kind='bar', figsize=(15, 6), stacked=True, color=gender_colours)\n",
                "plt.text(gender_df.shape[0] - 1, 1.1, 'Countries less likely to pitch female singers →', ha='right', va='center', fontsize=12)\n",
                "plt.text(0.05, 1.1, '← Countries more likely to pitch female singers', ha='left', va='center',  fontsize=12)\n",
                "plt.legend(['Female', 'Group', 'Male'], title=\"Performers' gender\", loc=[1, 1], fontsize=8,  bbox_to_anchor=(0.51, 0., 0.5, 0.5))\n",
                "plt.title('Gender of Artists at Eurovision by Performing Country', fontsize=16, pad=30)\n",
                "plt.xticks(rotation=-45, ha='left')\n",
                "plt.xlabel('')\n",
                "plt.ylabel('Ratio of performances')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "gender_df = df[['year', 'to_code2', 'gender']].copy().drop_duplicates()\n",
                "\n",
                "def ratio(gender, x): return len([a for a in x if a == gender]) / len(x)\n",
                "\n",
                "gender_df = gender_df.groupby('year').agg(\n",
                "    female=pd.NamedAgg(column='gender', aggfunc=lambda x: ratio('female', x)),\n",
                "    group=pd.NamedAgg(column='gender', aggfunc=lambda x: ratio('group', x)),\n",
                "    male=pd.NamedAgg(column='gender', aggfunc=lambda x: ratio('male', x)),\n",
                ")\n",
                "\n",
                "gender_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# subset gender_colours to genders in gender_df columns\n",
                "# gender_colours = gender_colours[gender_df.columns.to_list()]\n",
                "\n",
                "gender_df.plot(kind='bar', figsize=(15, 6), stacked=True, color=gender_colours)\n",
                "\n",
                "plt.legend(['Female', 'Group', 'Male'], title=\"Performers' gender\", loc=[1, 1], fontsize=8,  bbox_to_anchor=(0.51, 0., 0.5, 0.5))\n",
                "plt.title('Gender of Artists at Eurovision by Year', fontsize=16, pad=30)\n",
                "plt.xticks(rotation=-45, ha='left')\n",
                "plt.xlabel('')\n",
                "plt.ylabel('Ratio of performances')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "gender_df = df[['year', 'to_code2', 'gender', 'points']].copy()\n",
                "genders = list(gender_colours.keys())[:3]\n",
                "votes = []\n",
                "fig = plt.figure(figsize=(10, 5))\n",
                "ax = fig.add_subplot(1, 1, 1)\n",
                "for gender in genders:\n",
                "    votes_df = gender_df[gender_df['gender'] == gender]['points']\n",
                "    votes.append(votes_df)\n",
                "    plt.axvline(votes_df.mean(), color=gender_colours[gender], linestyle='dashed', linewidth=1)\n",
                "\n",
                "plt.hist(votes, density=True, bins=range(14), color=list(gender_colours.values())[:3], label=[gender.title() for gender in genders], align='left')\n",
                "plt.xlabel('Points awarded')\n",
                "plt.ylabel('Frequency')\n",
                "plt.title('Frequency of Points Awarded Categorised by Gender\\n(Dashed line indicates mean score)')\n",
                "plt.legend()\n",
                "plt.xticks(range(13))\n",
                "ax.set_xticklabels([str(i) for i in range(13)])\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: check if male get higher average votes. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Collective Visualisations"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Heatmap for correlation plot\n",
                "- Martin's plot\n",
                "- Geographical plots\n",
                "- Scatter plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "df_performance = df[['year', 'Artist', 'to_country', \n",
                "       'total_points', 'rank', 'to_code2', \n",
                "       'Official_languages', 'Language_sung', 'Contains_English',\n",
                "       'Contains_NonEnglish', 'Contains_Multiple_Languages',\n",
                "       'prop_emigrants_v2p', 'prop_emigrants_p2v', 'has_border',\n",
                "       'comps_without_win',\n",
                "       'Number_of_Languages', 'Contains_Own_Language', 'gender']].drop_duplicates()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "import matplotlib\n",
                "\n",
                "# Define the variables of interest and their data types\n",
                "vars_of_interest = {\n",
                "    'Contains_Own_Language': 'binary',\n",
                "    'Contains_Voting_Language': 'binary',\n",
                "    'Contains_English': 'binary',\n",
                "    'Contains_NonEnglish': 'binary',\n",
                "    'prop_emigrants_v2p': 'numeric', \n",
                "    'prop_emigrants_p2v': 'numeric', \n",
                "    'has_border': 'binary',\n",
                "    'gender': 'categorical', \n",
                "    'comps_without_win': 'numeric'\n",
                "}\n",
                "\n",
                "# Define the figure and axes\n",
                "nc = int(np.ceil(len(vars_of_interest)/2))\n",
                "fig, axes = plt.subplots(nrows=2, ncols=nc, figsize=(20, 10), sharey=True)\n",
                "\n",
                "# Loop through the dictionary\n",
                "for i, (key, value) in enumerate(vars_of_interest.items()):\n",
                "    j, k = 0, i\n",
                "    if i > (nc - 1):\n",
                "        j, k = 1, i - nc\n",
                "\n",
                "    if value == 'categorical':\n",
                "        sns.violinplot(ax=axes[j, k], x=key, y='points', data=df, color='tab:blue', inner=None, showmeans=True)\n",
                "    elif value == 'binary':\n",
                "        sns.violinplot(ax=axes[j, k], x=key, y='points', data=df, color='tab:blue', inner=None, showmeans=True)\n",
                "    else:\n",
                "        sns.regplot(ax=axes[j, k], x=key, y='points', data=df, ci=95, \n",
                "                    color='tab:blue', scatter_kws={'alpha': 0.4, 'edgecolor': 'none', 's': 20}, \n",
                "                    line_kws={'color': 'tab:orange'})\n",
                "\n",
                "        # if key contains Prop then log scale x axis\n",
                "        if key.startswith('prop'):\n",
                "            axes[j, k].set_xscale('log')\n",
                "            axes[j, k].set_xticks([0.01, 0.1, 1, 10, 100])\n",
                "            axes[j, k].get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
                "            axes[j, k].set_xlim(0.01, 1)\n",
                "\n",
                "    axes[j, k].set_ylim(-1, 13)\n",
                "    axes[j, k].set_xlabel(key.capitalize())\n",
                "    axes[j, k].set_ylabel('Votes')\n",
                "    axes[j, k].set_title(f'Votes vs. {key.capitalize()}')\n",
                "\n",
                "fig.suptitle('Relationships between Covariates and Eurovision Votes', fontsize=16)\n",
                "\n",
                "fig.tight_layout()\n",
                "fig.subplots_adjust(hspace=0.25)\n",
                "\n",
                "# Shuffle the bottom row along there are an odd number of variables\n",
                "if len(vars_of_interest) % 2 == 1:\n",
                "    axes[1][-1].remove()\n",
                "    # distance between two axes\n",
                "    if len(vars_of_interest) >= 3:\n",
                "        dist = axes[0][1].get_position().x0 - axes[0][0].get_position().x0\n",
                "        for ax in axes[1]:\n",
                "            pos = ax.get_position()\n",
                "            ax.set_position([pos.x0 + (dist / 2), pos.y0, pos.width, pos.height])\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# plot comps_without_win vs. points\n",
                "sns.violinplot(x='points', y='comps_without_win', data=df)\n",
                "# add jitter\n",
                "sns.stripplot(x='points', y='comps_without_win', data=df, jitter=True, color='black', alpha=0.2)\n",
                "\n",
                "plt.title('Votes vs. Number of Competitions without a Win')\n",
                "plt.ylabel('Number of Competitions without a Win')\n",
                "plt.xlabel('Votes')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df[['points', 'comps_without_win']].corr()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#| code-fold: true\n",
                "# One hot encoding for the gender variable\n",
                "df2 = pd.concat([df, pd.get_dummies(df['gender'])], axis=1)\n",
                "\n",
                "# correlation plot of numeric and binary variables\n",
                "df_corr = df2[['points', 'rank',\n",
                "       'total_points', 'Contains_English',\n",
                "       'Contains_NonEnglish', 'Contains_Multiple_Languages',\n",
                "       'Number_of_Languages', 'Contains_Own_Language', 'Contains_Voting_Language',\n",
                "       'female', 'male', 'group',\n",
                "       'prop_emigrants_v2p',  'prop_emigrants_p2v', 'has_border',\n",
                "       'comps_without_win']].corr()\n",
                "\n",
                "# heatmap of the correlation matrix\n",
                "sns.heatmap(df_corr.corr(), cmap='coolwarm', annot=True, fmt='.2f', annot_kws={'fontsize': 7})\n",
                "\n",
                "# replace _ in labels with space\n",
                "labels = [label.replace('_', ' ').title() for label in df_corr.columns]\n",
                "plt.xticks(np.arange(len(labels)), labels, rotation=-45, ha='left', va='top')\n",
                "plt.yticks(np.arange(len(labels)) + 0.5, labels, rotation=0, va='center')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "tags": []
            },
            "source": [
                "# Modelling\n",
                "\n",
                "Having explored all the data we have, we now turn to the question of using it to predict the results for Eurovision 2023.\n",
                "\n",
                "At the time that we carried out this modelling, Eurovision had not taken place yet. (You will see that the predictions here are *almost* the same as those described in [the Turing's public blog post](https://www.turing.ac.uk/blog/can-data-science-help-us-predict-winner-eurovision-2023), published before the competition!)\n",
                "\n",
                "However, since the competition has now concluded, we have also performed a retrospective analysis of how well our models performed.\n",
                "\n",
                "We developed three models: \n",
                "1. Baseline Model\n",
                "2. A Multi-level Bayesian Ordinal Regression Model\n",
                "3. A Ranked XGBoost Model\n",
                "\n",
                "\n",
                "We will discuss each of these below and highlight why each was selected, and how their results differ. \n",
                "\n",
                "It is a common practice to explore multiple modelling approaches. Different models have different strengths and weaknesses, including how challenging they are to implement, how capable they are at capturing complex structure in the data, and how easy they are to interpret once they have been fitted to the data. \n",
                "\n",
                "When selecting potential models, it is crucial to understand the complexity of the problem, as this informs our intuition about how well a model is expected to perform. It's easy to get caught up in the development of an increasingly complex model even when it might be performing no better than a much simpler model.\n",
                "\n",
                "It is a good idea to start with a simple model, which may be implemented quickly and provide a performance baseline. More complex models developed thereafter would be expected to outperform this baseline if the additional complexity is effective in capturing the patterns in the data.\n",
                "\n",
                "From this, it follows that there must be a way to evaluate the relative performance of the models: how well they model whats observed in real life. Often, models are evaluated with a process called [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)):\n",
                "- The available data is split into two datasets: one to fit the model, and the other for testing the model against examples that it has not be exposed to before.\n",
                "- It is expected that a good model will be able to make accurate predictions on the test data.\n",
                "- This offers a way to simulate the process of using the model to make predictions about events in the future.\n",
                "\n",
                "Before looking at three models in more detail, they can be summarised with the following:\n",
                "- All three models use the votes cast in previous Eurovision competition finals (1998-2022) to fit the parameters of the model.\n",
                "- All three models may be used to make predictions on how the 2023 competitors will rank in the final.\n",
                "- The Baseline model only looks at past performance in the competition to make predictions (i.e., it predicts the rank of each country for this year to be the average of its rankings over the past competitions it participated in)\n",
                "- The Bayesian Regression model and the XGBoost model take in additional information about the performances (e.g., language of the song lyrics) and the countries in the voter-performer pair (e.g., whether they share a land border).\n",
                "- The two more complex models predict each vote individually, after which the competition ranking may be determined.\n",
                "- The Bayesian model alone estimates a measure of uncertainty in the fitted model parameters - and hence any predictions generated by the model have an associated uncertainty."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (1) Baseline model\n",
                "\n",
                "Arguably the zeroth rule of data science is to *keep it simple*.\\*\n",
                "In other words, if we can capture patterns in the data using a less complicated model, this should be preferred over a more complex one.\n",
                "For this reason, the first analysis we did was to simply extrapolate the predicted rank from each country's prior performance in Eurovision.\n",
                "\n",
                "To do so, we assign each performance a *rescaled rank* ranging from 0 (last place) to 1 (first place):\n",
                "\n",
                "$$r_{\\text{rescaled}} = \\frac{n - r}{n - 1},$$\n",
                "\n",
                "where $n$ is the number of participants in the given year, and $r$ is the actual numeric rank. We calculated the average rescaled rank (across all final entries) for every participant of Eurovision 2023, and used this to rank the entrants.\n",
                "\n",
                "The 2022 data were excluded from the training set; we used this as validation data.\n",
                "\n",
                "<sup>\\* 'Zeroth' because we are in a Python notebook, and thus zero-indexing is mandatory.</sup>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_baseline(excluded_years=None):\n",
                "    if excluded_years is None:\n",
                "        excluded_years = []\n",
                "        \n",
                "    # Get maximum rank in each year (= number of countries participating)\n",
                "    df_rank_max = (df[['year', 'rank']]\n",
                "                .query('year not in @excluded_years')\n",
                "                .groupby('year')\n",
                "                .agg('max')\n",
                "                .rename({'rank': 'rank_max'}, axis=1)\n",
                "                )\n",
                "    \n",
                "    # Rescale rank to go from 0 = last place (rank = rank_max) to 1 = first place (rank = 1).\n",
                "    df_rank = (df[['to_country', 'year', 'rank']]\n",
                "                .query('year <= 2022')\n",
                "                .drop_duplicates()\n",
                "                .join(df_rank_max, how='left', on='year')\n",
                "                .assign(rescaled_rank=lambda x: (x['rank_max'] - x['rank'])/(x['rank_max'] - 1))\n",
                "                .groupby('to_country')\n",
                "                .agg({'rescaled_rank': 'mean'})\n",
                "                .sort_values('rescaled_rank', ascending=False)\n",
                "    )\n",
                "    \n",
                "    return df_rank\n",
                "    \n",
                "ranks_without_2022 = train_baseline(excluded_years=[2022])\n",
                "ranks_without_2022.head(n=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The table above shows the average rescaled rank for *all* countries observed in our dataset.\n",
                "To make predictions, we simply need to restrict the table entries to that year's participants.\n",
                "Let's see how well our baseline model does on predicting the 2022 results:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_baseline(rescaled_ranks, year):\n",
                "    if year <= 2022:\n",
                "        countries = df.query('year == @year')['to_country'].unique()\n",
                "    elif year == 2023:\n",
                "        countries = future['to_country'].unique()\n",
                "    predictions = (rescaled_ranks\n",
                "                   .query('to_country in @countries')\n",
                "                   .sort_values('rescaled_rank', ascending=False)\n",
                "                   .reset_index())\n",
                "    predictions['predicted_rank'] = predictions.index + 1\n",
                "    predictions = predictions.set_index('to_country')\n",
                "    return predictions\n",
                "    \n",
                "def get_actual_ranks(year):\n",
                "    return (df.query('year == @year')[['to_country', 'rank']]\n",
                "                .drop_duplicates()\n",
                "                .set_index('to_country')\n",
                "                .sort_values('rank'))\n",
                "                \n",
                "def join_predictions_and_actual(predicted_ranks, actual_ranks):\n",
                "    both = predicted_ranks.join(actual_ranks, validate='one_to_one').astype(int)\n",
                "    both = both.rename({'rank': 'actual_rank'}, axis=1)\n",
                "    return both[['predicted_rank', 'actual_rank']]\n",
                "    \n",
                "def get_spearman(predicted_ranks, actual_ranks):\n",
                "    both_ranks = join_predictions_and_actual(predicted_ranks, actual_ranks)\n",
                "    return both_ranks['predicted_rank'].corr(both_ranks['actual_rank'], method='spearman')\n",
                "    \n",
                "predictions_baseline = predict_baseline(ranks_without_2022, 2022)\n",
                "actual = get_actual_ranks(2022)\n",
                "both = join_predictions_and_actual(predictions_baseline, actual)\n",
                "\n",
                "print(f'Spearman correlation coefficient for 2022 is {get_spearman(predictions_baseline, actual):.3f}')\n",
                "both.head(n=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The Spearman coefficient is rather like its more famous cousin, the Pearson correlation, but is more suitable for ranked data.\n",
                "A value of 1 indicates that we have perfectly predicted the actual rankings, and -1 means that we have gotten it horribly wrong!\n",
                "\n",
                "In this respect, 0.239 does not look like a particularly impressive score.\n",
                "However, it should be borne in mind that Eurovision results can vary wildly from year to year, and perhaps a more valuable estimate of the accuracy of the model can be obtained by cross-validation.\n",
                "\n",
                "To do this, we train the model $N$ times (where $N = 24$ is the total number of years for which we have data), each time leaving out one year's worth of data, and using the model to predict that year's data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## NOTE: Slovakia only has one final entry in our dataset, in 1998.\n",
                "## So, when the model is 'trained' on all data excluding 1998, Slovakia doesn't get a rescaled_rank as there is no data to work with.\n",
                "## The 1998 predictions therefore don't include Slovakia (the Spearman coefficient is calculated based on all other entrants in 1998).\n",
                "\n",
                "all_years = df['year'].unique()\n",
                "\n",
                "def get_spearman_baseline_without(year):\n",
                "    rescaled_ranks = train_baseline(excluded_years=[year])\n",
                "    predictions_baseline = predict_baseline(rescaled_ranks, year)\n",
                "    actual = get_actual_ranks(year)\n",
                "    # Remove Slovakia from 1998\n",
                "    if year == 1998:\n",
                "        predictions_baseline = predictions_baseline.query('to_country != \"slovakia\"')\n",
                "        actual = actual.query('to_country != \"slovakia\"')\n",
                "    return(get_spearman(predictions_baseline, actual))\n",
                "    \n",
                "spearmans = [get_spearman_baseline_without(year) for year in all_years]\n",
                "\n",
                "print(f'Mean Spearman coefficient across {len(all_years)} years: {np.mean(spearmans)}')\n",
                "\n",
                "df_xv = pd.DataFrame({'year': all_years, 'spearman': spearmans})\n",
                "fig, ax = plt.subplots(figsize=(6, 4))\n",
                "ax.scatter(df_xv['year'], df_xv['spearman'], color='#6495ed')\n",
                "ax.set(xlabel='Year', ylabel='Spearman coefficient', title='Cross-validation: baseline method')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It turns out that *on average*, the historical results of a country at Eurovision are a half-decent indicator of how well they will perform in any given year.\n",
                "Of course, this is hardly a surprise.\n",
                "Interestingly, we can pick out years with lower Spearman correlations as being 'anomalies' in this regard, where an underdog won.\n",
                "The year with the lowest value (that's 2002) featured Latvia as the winner, and perhaps even more surprisingly, the UK finished third ([Jessica Garlick with *'Come Back'*](https://www.youtube.com/watch?v=2NSR5rSk0Cs)).\n",
                "When we write 'surprisingly', this is emphatically *not* us inserting our personal opinion: the baseline model in fact really dislikes the UK, assigning it the third-lowest average rescaled rank of all countries.\n",
                "Thus, any year where the UK performs well is a surprise to our model!\n",
                "\n",
                "Having looked at how good our model is at reproducing its own data, let's see what happens when we predict the 2023 results (now including all data from 1998 to 2022, inclusive, in our training)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions_2023 = predict_baseline(train_baseline(), 2023)\n",
                "\n",
                "n = len(predictions_2023)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(7, 8))\n",
                "ax.barh(width=predictions_2023['rescaled_rank'], y=np.arange(n), color='#4878D0')\n",
                "ax.set(\n",
                "    xlim=(0, predictions_2023['rescaled_rank'].max() * 1.1),\n",
                "    ylim=(-1, n),\n",
                "    yticks=np.arange(n),\n",
                "    yticklabels=predictions_2023.index.values,\n",
                "    xlabel='Average rescaled rank across all final appearances',\n",
                "    title='Baseline model: predicting 2023 results based on historical performance'\n",
                ")\n",
                "ax.set_yticklabels(ax.get_yticklabels(), fontsize=11)\n",
                "ax.invert_yaxis()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Our baseline model thus predicted Italy to come first, Sweden second, and Ukraine third, simply on the basis of them performing historically well at Eurovision.\n",
                "\n",
                "In 2023, the top three countries were Sweden (with [Loreen's *Tattoo*](https://www.youtube.com/watch?v=b3vJfR81xO0)), Finland (with [Käärijä's *Cha Cha Cha*](https://www.youtube.com/watch?v=znWi3zN8Ucg)), and Israel (with [Noa Kirel's *Unicorn*](https://www.youtube.com/watch?v=r4wbdKmM3bQ)).\n",
                "The full results of the final were as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "actual_ranks_2023 = (future.loc[~np.isnan(future['rank'])]\n",
                "                     .drop_duplicates(subset=['to_country'])\n",
                "                     .loc[:, ['to_country', 'rank']]\n",
                "                     .set_index('to_country'))\n",
                "\n",
                "actual_ranks_2023.sort_values(by='rank').T"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "With the benefit of this hindsight, we can therefore calculate the Spearman correlation coefficient for 2023.\n",
                "The Spearman coefficient is calculated only for countries which made the finals, since contestants eliminated in the semi-finals cannot really be assigned a 'rank'."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from adjustText import adjust_text\n",
                "\n",
                "finalists_2023 = actual_ranks_2023.index.unique()\n",
                "predictions_2023_finals = predictions_2023.query('to_country in @finalists_2023')\n",
                "\n",
                "print(f'Spearman correlation for 2023: {get_spearman(predictions_2023_finals, actual_ranks_2023):.3f}')\n",
                "\n",
                "both_2023 = join_predictions_and_actual(predictions_2023_finals, actual_ranks_2023)\n",
                "ax = both_2023.plot(kind='scatter', x='predicted_rank', y='actual_rank', figsize=(4, 4), color='#6495ed')\n",
                "ax.set(xlabel='Predicted rank (by baseline model)', ylabel='Actual rank', title='Baseline model: 2023 predictions vs. actual results')\n",
                "texts = []\n",
                "for i, txt in enumerate(both_2023.index):\n",
                "    t = ax.text(s=txt, x=both_2023.iloc[i]['predicted_rank'], y=both_2023.iloc[i]['actual_rank'],\n",
                "                ha='center', va='center', fontsize=8)\n",
                "    texts.append(t)\n",
                "ax.invert_xaxis(); ax.invert_yaxis()\n",
                "adjust_text(texts, avoid_self=False)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (2) Multi-level Bayesian Ordinal Regression Model\n",
                "\n",
                "The bayesian model we developed models individual voting instances, rather than directly modelling the rank of a performance amoungst the competitors. Unlike the other models, an inter-country bias term is fitted for each voter-performer pair to attempt to capture any voting bias or 'favoritism' between countries. This approach was inspired by work done by Marta Blangiardo and Gianluca Baio, presented in their paper [Evidence of bias in the Eurovision songcontest: modelling the votes using Bayesianhierarchical models](https://www.tandfonline.com/doi/full/10.1080/02664763.2014.909792).\n",
                "\n",
                "A drawback of this approach is that there is no constraint on the number of votes of a given score that one country may give out across round of voting. This is not representative of the real voting process that takes place, where each voter may only give out one score of 12, one of 10, etc. in a single round of voting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import stan\n",
                "import arviz as az\n",
                "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
                "import json\n",
                "import math\n",
                "\n",
                "# work around to get stan working in a notebook\n",
                "import nest_asyncio\n",
                "nest_asyncio.apply()\n",
                "del nest_asyncio"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Some futher pre-processing of the data is required to transform variables into a more suitable \n",
                "format. This includes encoding categorical variables as a binary representation and mapping the voting scores to a contiguous sequence from 1 to 11."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Given gender is a categoric variable with 3 classes, encode as binary w.r.t default gender='group'\n",
                "df['male'] = [1 if gender=='male' else 0 for gender in df['gender']]\n",
                "df['female'] = [1 if gender=='female' else 0 for gender in df['gender']]\n",
                "\n",
                "# Evaluate binary variables for boolean covariates to be used\n",
                "df['Contains_English_bin'] = df['Contains_English'].apply(lambda x: 1 if x else 0)\n",
                "df['Contains_Own_Language_bin'] = df['Contains_Own_Language'].apply(lambda x: 1 if x else 0)\n",
                "\n",
                "def format_votes(x):\n",
                "  if x == 12.:\n",
                "    return 10\n",
                "  elif x == 10.:\n",
                "    return 9\n",
                "  return int(x)\n",
                "df['indexed_votes'] = df['points'].apply(format_votes) + 1\n",
                "score_options = df['indexed_votes'].unique().tolist()\n",
                "score_options.sort()\n",
                "print(score_options)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next we arranged an integer indexed look-up table of voter-performer pairs which will be used later \n",
                "to fit the inter-country bias parameters in the model. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# build vector of voter/performer pair indicies and corresponding lookup tables\n",
                "performers = sorted(df['to_code2'].unique())\n",
                "voters = sorted(df['from_code2'].unique())\n",
                "print(f\"number of voters: {len(voters)}\")\n",
                "print(f\"number of performers: {len(performers)}\")\n",
                "diff =  set(voters) - set(performers)\n",
                "print(f'\\nThose who have voted but not performed: {diff}')\n",
                "\n",
                "# # create 0-indexed lookup tables for voter-performer pairings\n",
                "vptoi = {}\n",
                "itovp = {}\n",
                "counter = 0\n",
                "for p in performers:\n",
                "    for v in voters:\n",
                "        # only include v-p pairs that have occured in the data, different countries were voting and performing in different years\n",
                "        if ( p != v ) and ( not df.loc[ (df['from_code2'] == v) & (df['to_code2'] == p) ].empty ):\n",
                "            vptoi[f'{v}-{p}'] = counter\n",
                "            itovp[f'{counter}'] = f'{v}-{p}'\n",
                "            counter += 1\n",
                "\n",
                "df['vp'] = df.apply(lambda x: vptoi[f'{x[\"from_code2\"]}-{x[\"to_code2\"]}'], axis=1)\n",
                "print(f\"\\ncheck index of BE-HR: {vptoi['BE-HR']}\")\n",
                "print(f\"check index of BE-CY: {vptoi['BE-CY']}\")\n",
                "df[ [\"from_code2\",\"to_code2\",\"vp\"]].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# test/train split\n",
                "# Reserve data from 2019-2022 for testing model on unseen data\n",
                "print(f'full df shape: {df.shape}')\n",
                "df_train = df.loc[ df['year'] <= 2018 ]\n",
                "df_test = df.loc[ df['year'] > 2018 ]\n",
                "print(f'train df shape: {df_train.shape}')\n",
                "print(f'test df shape: {df_test.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To use PyStan to fit a model with Markov Chain Monte Carlo (MCMC) sampling, a Stan program is \n",
                "defined as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = \"\"\"\n",
                "// overload add function for adding an int to an array of ints\n",
                "functions {\n",
                "  array[] int add(array[] int x, int y) {\n",
                "      int x_size = size(x);\n",
                "      array[x_size] int z;\n",
                "      for (i in 1:x_size){\n",
                "        z[i] = x[i] + y;\n",
                "      }\n",
                "      return z;\n",
                "  }\n",
                "}\n",
                "data {\n",
                "  int<lower=2> S;\n",
                "  int<lower=0> N;   // total number of performances\n",
                "  int<lower=1> B;   // number of performance dependent covariates\n",
                "  int<lower=1> PHI; // number of voter/performer pair dependent covariates\n",
                "  int<lower=1> VP;  // number of voter/performer combinations\n",
                "\n",
                "  array[N] int<lower=1, upper=S> y;\n",
                "  matrix[N,B] xbeta;       // performance dependent covariates\n",
                "  matrix[VP,PHI] xphi;     // voter/performer pair dependent covariates\n",
                "  array[N] int<lower=0,upper=VP-1> vp;  // voter/performer pair index\n",
                "\n",
                "  int<lower=0> N_new; // number of predictions\n",
                "  matrix[N_new,B] xbeta_new;\n",
                "  array[N_new] int<lower=0,upper=VP-1> vp_new;\n",
                "\n",
                "}\n",
                "parameters {\n",
                "  vector[B] beta;\n",
                "  vector[PHI] phi;\n",
                "  vector[VP] alpha;\n",
                "  ordered[S-1] lambda;\n",
                "  real gamma;\n",
                "  real<lower=0> sigmaAlpha;\n",
                "}\n",
                "model {\n",
                "  gamma ~ normal(0, 10000);\n",
                "  beta ~ normal(0, 10000);\n",
                "  lambda ~ normal(0, 3.2);\n",
                "  sigmaAlpha ~ cauchy(0,1);\n",
                "\n",
                "  alpha ~ normal( xphi * phi, sigmaAlpha );\n",
                "  \n",
                "  // remembering that vp is 0-indexed and alpha is 1-indexed\n",
                "  y ~ ordered_logistic( gamma + alpha[ add(vp,1) ] + (xbeta * beta), lambda );\n",
                "\n",
                "}\n",
                "generated quantities {\n",
                "  vector[N] y_hat;\n",
                "  for (n in 1:N) {\n",
                "    y_hat[n] = ordered_logistic_rng( gamma + alpha[ add(vp[n],1) ] + (xbeta[n] * beta), lambda);\n",
                "  }\n",
                "\n",
                "  // out of sample predictions (scores we expect to observe for new data)\n",
                "  vector[N_new] y_pred;\n",
                "  for (n_new in 1:N_new) {\n",
                "    y_pred[n_new] = ordered_logistic_rng( gamma + alpha[ add(vp_new[n_new],1) ] + (xbeta_new[n_new] * beta), lambda);\n",
                "  }\n",
                "}\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data is arranged into matricies with some tranformations, scaling and substitutions for missing \n",
                "values which should improve the fitting process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# build xbeta matrix\n",
                "xbeta_train = df_train.loc[:,['Contains_English_bin','Contains_Own_Language_bin','male','female','comps_without_win']].values\n",
                "# minmax scaling of 'comps_since_last_win'\n",
                "scaler = MinMaxScaler() \n",
                "xbeta_train_norm = scaler.fit_transform(xbeta_train)\n",
                "\n",
                "xbeta_test = df_test.loc[:,['Contains_English_bin','Contains_Own_Language_bin','male','female','comps_without_win']].values\n",
                "# minmax scaling of 'comps_since_last_win'\n",
                "xbeta_test_norm = scaler.transform(xbeta_test)\n",
                "\n",
                "# build xphi matrix\n",
                "xphi = np.zeros((len(vptoi), 2))\n",
                "migration_means = []\n",
                "zero_count = 0\n",
                "nan_count = 0\n",
                "for pair,idx in vptoi.items():\n",
                "    v = pair[:2]\n",
                "    p = pair[-2:]\n",
                "    vp = df.loc[ (df['from_code2'] == v) & (df['to_code2'] == p) ]\n",
                "    xphi[idx][0] = 1.0 if vp['has_border'].unique() else 0.0\n",
                "\n",
                "    migration_series = vp['prop_emigrants_v2p']\n",
                "    if migration_series.isnull().any():\n",
                "        # if no migration data is available, use the plot below to infer the most appropriate substitute value\n",
                "        # this should be a better alternative to assuming 0 migration\n",
                "        xphi[idx][1] = math.exp(-9) - 2.6e-08/2\n",
                "        nan_count += 1\n",
                "    else:\n",
                "        mean_migration = migration_series.mean()\n",
                "        xphi[idx][1] = mean_migration\n",
                "\n",
                "        # below lines for informational purpose\n",
                "        if mean_migration == 0.0:\n",
                "            zero_count +=1\n",
                "        migration_means.append(mean_migration)\n",
                "\n",
                "print(f'mean = 0.0 count: {zero_count}')\n",
                "print(f'mean = nan count: {nan_count}')\n",
                "print(f'\\nNote that {round(100*nan_count/len(vptoi),2)}% of the v-p pairs get the substitute value for migration intensity because there was no migration information.')\n",
                "plt.hist(np.log(np.array(migration_means) + 2.6e-08/2)) # translate by half of smallest non-zero value\n",
                "plt.title('distribution of available non-zero migration data (used to infer missing data)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# standardise the migration intensity feature in xphi with a log transform and standardisation\n",
                "mig_ints = xphi[:,1]\n",
                "mig_ints_sort = np.sort(mig_ints)\n",
                "print(f'smallest non-zero value: {mig_ints_sort[mig_ints_sort != 0][0]}')\n",
                "\n",
                "mig_ints_log = np.log10(mig_ints + 2.6e-08/2)   # rule of thumb, half of smallest non-zero value\n",
                "std_scaler = StandardScaler()\n",
                "mig_ints_log_std = std_scaler.fit_transform(mig_ints_log.reshape(-1, 1))\n",
                "\n",
                "# write scaler version of xphi\n",
                "xphi_norm = xphi.copy()\n",
                "xphi_norm[:,1] = mig_ints_log_std.reshape((2175,))\n",
                "\n",
                "plt.hist(xphi_norm[:,1],bins=100)\n",
                "plt.title(f'normalised migration intensity values for {len(vptoi)} v-p pairs')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The model is fit in the code cell below. As a word of warning, the sampling process is quite time-consuming."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = {\n",
                "    'S': 11,\n",
                "    'N': df_train.shape[0],\n",
                "    'B': xbeta_train_norm.shape[1],\n",
                "    'PHI' : xphi_norm.shape[1],\n",
                "    'VP' : xphi_norm.shape[0],\n",
                "    'y': df_train['indexed_votes'].values,\n",
                "    'xbeta': xbeta_train_norm,\n",
                "    'xphi' : xphi_norm,\n",
                "    'vp' : df_train['vp'].values,\n",
                "    'N_new': df_test.shape[0],\n",
                "    'xbeta_new': xbeta_test_norm,\n",
                "    \"vp_new\" : df_test['vp'].values\n",
                "}\n",
                "\n",
                "posterior = stan.build(model, data=data)\n",
                "# fit = posterior.sample(num_chains=2, num_warmup=1000, num_samples=300)\n",
                "fit = posterior.sample(num_chains=2, num_warmup=100, num_samples=100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "az_fit = az.from_pystan(\n",
                "    posterior=fit, \n",
                "    observed_data=\"y\", \n",
                "    posterior_predictive=\"y_hat\",\n",
                "    predictions=\"y_pred\", \n",
                "    posterior_model=posterior)\n",
                "\n",
                "az.plot_trace(az_fit, [\"beta\",\"lambda\"], figsize=(20,8), legend=True)\n",
                "az.plot_trace(az_fit, [\"beta\"], figsize=(25,35), legend=True, compact=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "axes = az.plot_forest(az_fit,\n",
                "                        kind='forestplot',\n",
                "                        combined=True,\n",
                "                        quartiles=False,\n",
                "                        hdi_prob=0.89,\n",
                "                        var_names=['beta','phi','sigmaAlpha']\n",
                "                        )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## (3) Ranked XGBoost Model\n",
                "\n",
                "Our XGBoost model also modelled the competition at the level of the individual votes. However, it was designed to model the behaviour of a voting country given a set of performances and a constrained set of votes to hand out (1, 2, 3, 4, 5, 6, 7, 8, 10, 12). In the same way as the Bayesian model, once the votes are cast the total score for each performer can be evaluated, and the competition ranking determined.\n",
                "\n",
                "A ranked XGBoost (Extreme Gradient Boosting) model is a type of machine learning model that is used to predict rankings or orders of items.\n",
                "\n",
                "The \"XGBoost\" part of the model name refers to the specific algorithm that is used to train the model. XGBoost is a gradient boosting algorithm that works by iteratively improving a weak model based on decision trees by adding new models that correct its errors. This process continues until the model is able to accurately predict the target variable, in this case the rankings of the products.\n",
                "\n",
                "The \"ranked\" aspect of the model refers to the fact that it is specifically designed to predict rankings or orders, rather than just predicting individual values or classifications. This is useful in scenarios where the order or ranking of items is important, such as in search engine results or recommendation systems.\n",
                "\n",
                "Overall, a ranked XGBoost model is a powerful machine learning tool that can be used to predict rankings or orders of items, based on various factors that may influence their positions in the ranking. This technique is often used to train XGBoost models for ranking tasks, such as search engine ranking or recommendation systems."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclusions\n",
                "\n",
                "Round everything up, draw conclusions."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
